# Revenge of the Nerds
**카테고리**: Mindset
**난이도**: 중급
**출판일**: N/A
**원문**: https://paulgraham.com/icad.html
---
## 요약 (Summary)

🎯 괴짜들의 복수가 뭘까요?

✨ 핵심 내용 요약

Paul Graham이 선언합니다: **괴짜들(nerds)이 이겼습니다**. 학교에서 인기 없던 아이들이 세상을 바꿨습니다.

1980년대: Bill Gates, Steve Jobs - 학교에서 왕따. 2000년대: Larry Page, Mark Zuckerberg - 똑같이 괴짜. 하지만 그들이 세상을 지배합니다. 왜? **기술이 힘이 되었기 때문입니다**. 과거에는 근육이나 인맥이 중요했습니다. 하지만 인터넷 시대에는 코딩 능력이 중요합니다. Graham의 메시지: 학교에서 인기 없어도 괜찮습니다. 좋아하는 것(프로그래밍, 수학, 과학)에 집중하세요. 10년 후 당신이 이깁니다. 한국 학생들에게: "공부만 하는 애"라고 놀림받아도 괜찮습니다.

**핵심 포인트**
• 괴짜들이 세상을 바꿨습니다
• 기술이 새로운 힘입니다
• 인기보다 실력이 중요합니다

🚀 오늘 바로 실천해볼 한 가지
남들이 "이상하다"고 하는 취미나 관심사에 더 시간을 쓰세요. 그게 당신의 경쟁력입니다.

---

## 한국어 번역 (Korean Translation)

스타트업을 시작하고 싶나요?Y Combinator에서 자금을 지원받으세요.2002년 5월 "우리는 C++ 프로그래머를 쫓았습니다. 우리는 그들 중 많은 사람들을 Lisp의 중간쯤으로 끌고 갔습니다." - Guy Steele, Java 사양의 공동 저자 소프트웨어 사업에서는 뾰족한 학자들과 또 다른 똑같이 강력한 세력인 뾰족한 머리의 상사들 사이에 지속적인 투쟁이 있습니다.뾰족머리 사장님이 누군지 다들 아시죠?기술 분야의 대부분의 사람들은 이 만화 캐릭터를 알아볼 뿐만 아니라 자신이 모델로 삼은 회사의 실제 인물도 알고 있다고 생각합니다. 뾰족한 머리의 상사는 그들 자신에게는 공통적이지만 좀처럼 함께 볼 수 없는 두 가지 특성을 기적적으로 결합합니다. 즉 (a) 그는 기술에 대해 아무것도 모르고 (b) 기술에 대해 매우 강한 의견을 가지고 있습니다. 예를 들어, 소프트웨어를 작성해야 한다고 가정해 보겠습니다.뾰족한 머리의 상사는 이 소프트웨어가 어떻게 작동해야 하는지 전혀 모르고 프로그래밍 언어를 구별할 수도 없지만 어떤 언어로 작성해야 하는지 알고 있습니다. 정확합니다.그는 Java로 작성해야 한다고 생각합니다. 왜 그렇게 생각합니까?뾰족머리 보스의 뇌 속을 들여다보자.그 사람의 생각은 대략 이렇습니다.자바는 표준이다.나는 항상 언론에서 그것에 대해 읽었기 때문에 그럴 것이라는 것을 알고 있습니다.표준이므로 사용하는데 문제는 없습니다.그리고 그것은 또한 항상 많은 Java 프로그래머가 있다는 것을 의미합니다. 따라서 나를 위해 일하는 프로그래머가 지금 그만두면 신비하게 나를 위해 일하는 프로그래머가 항상 그렇듯이 나는 쉽게 그들을 교체할 수 있습니다.글쎄, 이것이 그렇게 불합리하게 들리지는 않습니다.하지만 이 모든 것은 하나의 암묵적인 가정에 기초하고 있으며, 그 가정은 거짓임이 밝혀졌습니다.뾰족한 머리의 상사는 모든 프로그래밍 언어가 거의 동일하다고 믿습니다.만약 그게 사실이라면, 그는 목표에 딱 맞았을 것입니다.언어가 모두 동일하다면 다른 사람들이 사용하는 언어를 사용하십시오. 하지만 모든 언어가 동일하지는 않으며, 언어 간의 차이점을 이해하지 않고도 이를 증명할 수 있다고 생각합니다.1992년에 뾰족한 머리의 상사에게 어떤 언어 소프트웨어를 작성해야 하는지 묻는다면, 그는 지금처럼 주저하지 않고 대답했을 것입니다.소프트웨어는 C++로 작성되어야 합니다.하지만 언어가 모두 동일하다면 왜 뾰족한 머리의 상사의 의견이 바뀌어야 합니까?사실, 왜 자바 개발자들이 굳이 새로운 언어를 만들려고 애썼을까요? 아마도 새로운 언어를 만든다면 그것은 사람들이 이미 가지고 있던 것보다 어떤 면에서는 더 낫다고 생각하기 때문일 것입니다.실제로 Gosling은 첫 번째 Java 백서에서 Java가 C++의 일부 문제를 해결하도록 설계되었음을 분명히 밝혔습니다.그래서 거기에 있습니다: 언어가 모두 동일하지는 않습니다.뾰족한 머리의 상사의 뇌를 통해 자바로 가는 길을 따라가다가 자바의 역사를 통해 그 기원으로 돌아가면, 결국 처음에 가졌던 가정과 모순되는 아이디어를 갖게 됩니다. 그렇다면 누가 옳은가요?제임스 고슬링인가, 아니면 뾰족한 머리의 상사인가?당연히 Gosling이 옳습니다.일부 언어는 특정 문제에 대해 다른 언어보다 더 좋습니다.그리고 그것은 몇 가지 흥미로운 질문을 제기합니다.Java는 특정 문제에 대해 C++보다 더 나은 성능을 발휘하도록 설계되었습니다.어떤 문제가 있나요?Java는 언제 더 좋고 C++는 언제인가요?다른 언어가 두 언어보다 더 나은 상황이 있습니까? 이 질문을 고려하기 시작하면 실제 웜 캔을 연 것입니다.뾰족한 머리의 상사가 문제를 완전히 복잡하게 생각해야 한다면 그의 두뇌는 폭발할 것입니다.모든 언어가 동등하다고 생각하는 한, 가장 추진력이 있을 것 같은 언어를 선택하기만 하면 되고, 그것은 기술보다는 패션의 문제이기 때문에 어쩌면 그도 정답을 얻을 수 있을 것이다.그러나 언어가 다양하면 갑자기 두 가지 연립방정식을 풀어야 하며, 그가 전혀 모르는 두 가지, 즉 그가 해결해야 하는 문제에 대한 20개 정도의 주요 언어의 상대적 적합성과 프로그래머, 라이브러리를 찾을 확률 사이에서 최적의 균형을 찾으려고 노력해야 합니다.

, 등 각각에 대해.그것이 문 반대편에 있다면, 뾰족한 머리의 상사가 문을 열려고 하지 않는 것도 당연합니다. 모든 프로그래밍 언어가 동등하다고 믿는 것의 단점은 그것이 사실이 아니라는 것입니다.하지만 장점은 삶이 훨씬 단순해진다는 것입니다.그리고 내 생각엔 이것이 이 아이디어가 그렇게 널리 퍼진 주된 이유라고 생각합니다.그것은 편안한 아이디어입니다. 우리는 Java가 멋지고 새로운 프로그래밍 언어이기 때문에 꽤 훌륭할 것이라는 것을 알고 있습니다.아니면 그럴까요?프로그래밍 언어의 세계를 멀리서 보면 자바가 최신인 것 같습니다.(멀리서 보면 썬이 지불한 크고 번쩍이는 광고판만 보입니다.) 하지만 이 세상을 가까이서 보면 어느 정도 멋짐이 있다는 것을 알게 됩니다.해커 하위문화에는 Java보다 훨씬 더 멋지다고 여겨지는 Perl이라는 또 다른 언어가 있습니다.예를 들어 Slashdot은 Perl에 의해 생성됩니다.나는 당신이 Java Server Pages를 사용하는 사람들을 찾을 수 없을 것이라고 생각합니다.그러나 사용자가 Perl을 무시하는 경향이 있고 더 많은 것이 기다리고 있는 Python이라는 또 다른 새로운 언어가 있습니다. Java, Perl, Python 순서로 이러한 언어를 살펴보면 흥미로운 패턴을 발견할 수 있습니다.적어도 당신이 Lisp 해커라면 이 패턴을 발견할 것입니다.각각은 점차적으로 Lisp와 비슷해졌습니다.Python은 많은 Lisp 해커가 실수로 간주하는 기능까지 복사합니다.간단한 Lisp 프로그램을 한 줄씩 Python으로 변환할 수 있습니다.때는 2002년이고 프로그래밍 언어는 1958년을 거의 따라잡았습니다. 수학 따라잡기내 말은 Lisp는 1958년에 John McCarthy에 의해 처음 발견되었고 대중적인 프로그래밍 언어가 이제서야 그가 당시 개발한 아이디어를 따라잡고 있다는 것입니다. 자, 어떻게 그게 사실일 수 있겠습니까?컴퓨터 기술은 매우 빠르게 변화하는 기술이 아닌가?1958년에 컴퓨터는 손목시계의 처리 능력을 갖춘 냉장고 크기의 거대 기업이었습니다.오래된 기술이 어떻게 최신 개발보다 우수할 수 있고 관련성이 있을 수 있습니까?그 방법을 알려드리겠습니다.Lisp는 실제로 프로그래밍 언어로 설계되지 않았기 때문입니다. 적어도 오늘날 의미하는 의미에서는 그렇지 않습니다.우리가 프로그래밍 언어로 의미하는 것은 컴퓨터에게 무엇을 해야 할지 지시하는 데 사용하는 것입니다.McCarthy는 결국 이러한 의미에서 프로그래밍 언어를 개발하려고 했지만 실제로 우리가 갖게 된 Lisp는 그가 이론적 연습으로 수행한 별도의 작업, 즉 Turing Machine에 대한 보다 편리한 대안을 정의하려는 노력을 기반으로 했습니다.McCarthy가 나중에 말했듯이 Lisp가 Turing 기계보다 깔끔하다는 것을 보여주는 또 다른 방법은 범용 Lisp 함수를 작성하고 그것이 범용 Turing 기계의 설명보다 더 간단하고 이해하기 쉽다는 것을 보여주는 것입니다.이것이 바로 Lisp 표현식의 값을 계산하는 Lisp 함수 eval...이었습니다.... eval을 작성하려면 Lisp 함수를 Lisp 데이터로 나타내는 표기법을 고안해야 했고, 이러한 표기법은 실제로 Lisp 프로그램을 표현하는 데 사용될 것이라는 생각 없이 논문의 목적에 맞게 고안되었습니다.그 다음에 일어난 일은 1958년 말, McCarthy의 대학원생 중 한 명인 Steve Russell이 eval의 정의를 보고 이를 기계어로 번역하면 결과가 Lisp 해석기가 될 것임을 깨달았다는 것입니다. 당시에는 이것은 큰 놀라움이었습니다.McCarthy가 나중에 인터뷰에서 이에 대해 말한 내용은 다음과 같습니다. Steve Russell이 "이봐, 내가 이 평가를 프로그래밍하는 게 어때?"라고 말했고, 저는 그에게 "호, 호, 당신은 이론과 실제를 혼동하고 있습니다. 이 평가는 읽기를 위한 것이지 컴퓨팅을 위한 것이 아닙니다."라고 말했습니다.그러나 그는 계속해서 해냈습니다.즉, 그는 내 논문의 평가판을 [IBM] 704 기계 코드로 컴파일하고 버그를 수정한 다음 이것을 Lisp 인터프리터로 광고했는데, 확실히 그랬습니다.그래서 그 시점에서 Lisp는 본질적으로 오늘날과 같은 형태를 가졌습니다.... 갑자기, 제 생각에는 몇 주 만에 McCarthy는 자신의 이론적인 작업이 실제 프로그래밍 언어로 변환된 것을 발견했습니다. 그리고 그가 의도했던 것보다 더 강력한 언어였습니다. 그래서 이 이유에 대한 간단한 설명은 다음과 같습니다.

1950년대 언어가 쓸모없다는 것은 기술이 아니라 수학이고 수학은 진부해지지 않는다는 점입니다.Lisp와 비교해야 할 올바른 것은 1950년대 하드웨어가 아니라 1960년에 발견되었으며 여전히 가장 빠른 범용 정렬인 Quicksort 알고리즘입니다. 1950년대부터 여전히 남아 있는 또 다른 언어인 Fortran이 있으며 이는 언어 설계에 대한 반대 접근 방식을 나타냅니다.Lisp는 예기치 않게 프로그래밍 언어로 변한 이론의 일부였습니다.Fortran은 의도적으로 프로그래밍 언어로 개발되었지만 지금은 매우 낮은 수준의 언어로 간주됩니다. 1956년에 개발된 언어인 Fortran I은 현재의 Fortran과는 매우 다른 동물이었습니다.Fortran 저는 수학을 포함한 어셈블리 언어에 가깝습니다.어떤 면에서는 최신 어셈블리 언어보다 덜 강력했습니다.서브루틴은 없었습니다. 예를 들어 분기만 있었습니다.현재의 Fortran은 이제 Fortran보다 Lisp에 더 가깝습니다. I.Lisp와 Fortran은 두 개의 별도 진화 나무의 줄기였으며, 하나는 수학과 기계 아키텍처에 뿌리를 두고 있습니다.이 두 나무는 그 이후로 수렴해 왔습니다.Lisp는 처음에는 강력하게 시작했고 이후 20년 동안 빠르게 성장했습니다.소위 주류 언어라고 불리는 언어는 빠르게 시작되었고, 다음 40년 동안 점차적으로 더욱 강력해졌으며, 지금까지 가장 발전된 언어는 Lisp에 상당히 가깝습니다.가깝지만 여전히 몇 가지가 빠져 있습니다....Lisp를 다르게 만든 이유 Lisp가 처음 개발되었을 때 Lisp는 9가지 새로운 아이디어를 구현했습니다.이들 중 일부는 이제 우리가 당연하게 여기고, 다른 일부는 고급 언어에서만 볼 수 있으며, 두 개는 여전히 Lisp에 고유합니다.9가지 아이디어는 주류에 의해 채택된 순서에 따라 조건부입니다.조건문은 if-then-else 구조입니다.우리는 지금 이것을 당연하게 여기지만 포트란에는 그런 것이 없었습니다.기본 기계 명령어에 밀접하게 기반한 조건부 goto만 있었습니다.함수 유형입니다.Lisp에서 함수는 정수나 문자열과 같은 데이터 유형입니다.이는 리터럴 표현을 가지며, 변수에 저장될 수 있고, 인수로 전달될 수 있습니다.재귀.Lisp는 이를 지원하는 최초의 프로그래밍 언어였습니다.동적 타이핑.Lisp에서는 모든 변수가 사실상 포인터입니다.값은 변수가 아닌 유형을 갖는 것이며, 변수를 할당하거나 바인딩한다는 것은 포인터가 가리키는 것이 아니라 포인터를 복사하는 것을 의미합니다.쓰레기 수거.표현식으로 구성된 프로그램.Lisp 프로그램은 각각 값을 반환하는 표현식 트리입니다.이는 표현식과 명령문을 구별하는 Fortran 및 대부분의 후속 언어와 대조됩니다. 명령문을 중첩할 수 없기 때문에 Fortran I에서 이러한 구별을 갖는 것은 자연스러운 일이었습니다.따라서 수학이 작동하려면 표현식이 필요하지만 다른 어떤 것도 값을 반환하도록 만드는 것은 의미가 없습니다. 왜냐하면 이를 기다리는 것이 없기 때문입니다. 이러한 제한은 블록 구조 언어가 등장하면서 사라졌지만 그때는 너무 늦었습니다.표현과 진술 사이의 구별이 확고해졌습니다.그것은 Fortran에서 Algol로, 그리고 두 후손 모두에게 퍼졌습니다.기호 유형입니다.기호는 사실상 해시 테이블에 저장된 문자열에 대한 포인터입니다.따라서 각 문자를 비교하는 대신 포인터를 비교하여 동일성을 테스트할 수 있습니다.기호 및 상수 트리를 사용하는 코드 표기법입니다.항상 전체 언어가 있습니다.읽기 시간, 컴파일 시간, 런타임 사이에는 실질적인 차이가 없습니다.읽는 동안 코드를 컴파일하거나 실행할 수 있고, 컴파일하는 동안 코드를 읽거나 실행할 수 있으며, 런타임에 코드를 읽거나 컴파일할 수 있습니다. 읽기 시간에 코드를 실행하면 사용자가 Lisp의 구문을 다시 프로그래밍할 수 있습니다.컴파일 타임에 코드를 실행하는 것이 매크로의 기초입니다.런타임 시 컴파일은 Emacs와 같은 프로그램에서 확장 언어로 Lisp를 사용하는 기본입니다.런타임 시 읽기를 통해 프로그램은 최근 XML로 재창조된 아이디어인 s-표현식을 사용하여 통신할 수 있습니다.Lisp가 처음 등장했을 때 이러한 아이디어는 주로 t에서 사용 가능한 하드웨어에 따라 결정되는 일반적인 프로그래밍 관행과는 거리가 멀었습니다.

그는 1950년대 후반.시간이 지남에 따라 일련의 인기 언어로 구현된 기본 언어는 점차적으로 Lisp로 발전했습니다.아이디어 1-5는 이제 널리 퍼져 있습니다.6번이 주류에 등장하기 시작했습니다.Python의 형식은 7이지만 이에 대한 구문은 없는 것 같습니다. 숫자 8의 경우 이것이 가장 흥미로울 수 있습니다.아이디어 8과 9는 우연히 Lisp의 일부가 되었습니다. Steve Russell이 McCarthy가 결코 구현하려고 의도하지 않았던 것을 구현했기 때문입니다.그러나 이러한 아이디어는 Lisp의 이상한 외관과 가장 독특한 특징 모두에 대한 책임이 있는 것으로 밝혀졌습니다.Lisp는 이상한 구문을 갖고 있기 때문이 아니라 구문이 없기 때문에 이상하게 보입니다.다른 언어가 파싱될 때 이면에 구축되는 파싱 트리에서 직접 프로그램을 표현하는데, 이 트리는 Lisp 데이터 구조인 목록으로 구성됩니다. 언어를 자체 데이터 구조로 표현하는 것은 매우 강력한 기능으로 밝혀졌습니다.아이디어 8과 9는 프로그램을 작성하는 프로그램을 작성할 수 있음을 의미합니다.그것은 기괴한 생각처럼 들릴지 모르지만 Lisp에서는 일상적인 일입니다.이를 수행하는 가장 일반적인 방법은 매크로라는 것을 사용하는 것입니다. "매크로"라는 용어는 Lisp에서 다른 언어의 의미를 의미하지 않습니다.Lisp 매크로는 약어부터 새로운 언어의 컴파일러까지 무엇이든 될 수 있습니다.Lisp를 실제로 이해하고 싶거나 프로그래밍 지평을 확장하고 싶다면 매크로에 대해 더 많이 배울 것입니다. 매크로(Lisp 의미에서)는 제가 아는 한 여전히 Lisp에 고유합니다.이는 부분적으로 매크로를 갖기 위해서는 언어를 Lisp처럼 이상하게 보이게 만들어야 하기 때문입니다.또한 최종적인 힘의 증가를 추가하면 더 이상 새로운 언어를 발명했다고 주장할 수 없고 단지 Lisp의 새로운 방언만 발명했다고 주장할 수 있기 때문일 수도 있습니다. 나는 이것을 대부분 농담으로 언급하지만 그것은 사실입니다.car, cdr, cons, quote, cond,atom, eq 및 목록으로 표현된 함수에 대한 표기법이 있는 언어를 정의하면 나머지 Lisp를 모두 구축할 수 있습니다.이것이 사실 Lisp의 품질을 정의하는 것입니다. McCarthy가 Lisp의 모양을 제공하도록 하기 위한 것이었습니다. 언어가 중요한 곳 Lisp가 주류 언어가 점근적으로 접근하는 일종의 한계를 나타낸다고 가정해 보겠습니다. 이는 실제로 소프트웨어를 작성하는 데 Lisp를 사용해야 한다는 의미입니까?덜 강력한 언어를 사용하면 얼마나 손해를 보나요?때로는 혁신의 가장자리에 있지 않는 것이 더 현명하지 않나요?그리고 인기는 어느 정도 그 자체의 정당성이 있지 않습니까?예를 들어, 뾰족한 머리의 상사가 프로그래머를 쉽게 고용할 수 있는 언어를 사용하고 싶어하는 것이 옳지 않습니까? 물론 프로그래밍 언어 선택이 크게 중요하지 않은 프로젝트도 있습니다.일반적으로 응용 프로그램의 요구 사항이 높을수록 강력한 언어를 사용하면 더 많은 이점을 얻을 수 있습니다.그러나 많은 프로젝트는 전혀 요구되지 않습니다.대부분의 프로그래밍은 아마도 작은 글루 프로그램 작성으로 구성되며, 작은 글루 프로그램의 경우 이미 익숙하고 필요한 모든 작업에 적합한 라이브러리가 있는 언어를 사용할 수 있습니다.한 Windows 앱에서 다른 앱으로 데이터를 공급해야 한다면 물론 Visual Basic을 사용하십시오. Lisp에서도 간단한 글루 프로그램을 작성할 수 있지만(나는 이것을 데스크톱 계산기로 사용합니다) Lisp와 같은 언어의 가장 큰 승리는 치열한 경쟁에 직면하여 어려운 문제를 해결하기 위해 정교한 프로그램을 작성해야 하는 스펙트럼의 반대편에 있습니다.좋은 예는 ITA 소프트웨어가 Orbitz에 라이선스를 부여한 항공사 요금 검색 프로그램입니다.이들은 이미 확고한 두 경쟁사인 Travelocity와 Expedia가 지배하고 있는 시장에 진입하여 기술적으로 굴욕감을 안겨준 것 같습니다. ITA 애플리케이션의 핵심은 여전히 ​​메인프레임 시대의 프로그래밍 기술을 사용하고 있는 경쟁사보다 훨씬 더 많은 가능성을 검색하는 200,000라인의 Common Lisp 프로그램입니다.(ITA도 어떤 의미에서는 메인프레임 시대의 프로그래밍 언어를 사용하고 있지만)

ITA의 코드를 본 적이 있지만 최고의 해커 중 한 명에 따르면 그들은 많은 매크로를 사용하며 그 말을 들어도 놀랍지 않습니다. 구심력드문 기술을 사용하는 데 비용이 전혀 들지 않는다는 말은 아닙니다.뾰족한 머리의 상사가 이것에 대해 걱정하는 것이 완전히 틀린 것은 아닙니다.하지만 위험을 이해하지 못하기 때문에 위험을 확대하는 경향이 있습니다. 덜 일반적인 언어를 사용하면 발생할 수 있는 세 가지 문제를 생각해 볼 수 있습니다.귀하의 프로그램은 다른 언어로 작성된 프로그램과 제대로 작동하지 않을 수 있습니다.마음대로 사용할 수 있는 라이브러리가 더 적을 수도 있습니다.그리고 프로그래머를 고용하는 데 어려움을 겪을 수도 있습니다. 이들 각각은 얼마나 큰 문제입니까?첫 번째의 중요성은 전체 시스템을 제어할 수 있는지 여부에 따라 달라집니다.버그가 많고 폐쇄적인 운영 체제(이름은 언급하지 않음) 위에서 원격 사용자 컴퓨터에서 실행해야 하는 소프트웨어를 작성하는 경우 OS와 동일한 언어로 애플리케이션을 작성하는 것이 이점이 있을 수 있습니다.그러나 ITA처럼 전체 시스템을 제어하고 모든 부분의 소스 코드를 가지고 있다면 원하는 언어를 사용할 수 있습니다.비호환성이 발생하면 직접 해결할 수 있습니다. 서버 기반 응용 프로그램에서는 가장 진보된 기술을 사용하여 벗어날 수 있으며 이것이 조나단 에릭슨이 "프로그래밍 언어 르네상스"라고 부르는 주요 원인이라고 생각합니다.이것이 우리가 Perl이나 Python과 같은 새로운 언어에 대해 듣는 이유이기도 합니다.사람들이 Windows 앱을 작성하는 데 이러한 언어를 사용하기 때문에 이러한 언어에 대해 듣는 것이 아니라 서버에서 사용하기 때문입니다.그리고 소프트웨어가 데스크톱에서 서버로 이동함에 따라(Microsoft도 이를 포기한 것으로 보임) 중도 기술을 사용하려는 압력이 점점 줄어들 것입니다. 라이브러리의 경우 그 중요성은 응용 프로그램에 따라 달라집니다.덜 까다로운 문제의 경우 라이브러리의 가용성이 언어의 본질적인 힘보다 중요할 수 있습니다.손익분기점은 어디인가?정확하게 말하기는 어렵지만 어디에 있든 애플리케이션이라고 부를 만한 것이 부족합니다.회사가 자신을 소프트웨어 사업에 종사한다고 생각하고 제품 중 하나가 될 애플리케이션을 작성하고 있다면 아마도 여러 명의 해커가 참여하고 작성하는 데 최소 6개월이 걸릴 것입니다.그 정도 규모의 프로젝트에서는 아마도 강력한 언어가 기존 라이브러리의 편리함을 능가하기 시작할 것입니다. 뾰족한 상사의 세 번째 걱정인 프로그래머 채용의 어려움은 붉은 청어라고 생각합니다.결국 몇 명의 해커를 고용해야 합니까?이제 우리 모두는 소프트웨어가 10명 미만의 팀에서 가장 잘 개발된다는 것을 알고 있습니다.그리고 누구나 들어본 적이 있는 모든 언어에 대해 그 정도 규모의 해커를 고용하는 데 어려움을 겪어서는 안 됩니다.10명의 Lisp 해커를 찾을 수 없다면 귀하의 회사는 아마도 소프트웨어 개발을 위한 잘못된 도시에 기반을 두고 있는 것입니다. 사실 더 강력한 언어를 선택하면 필요한 팀의 규모가 줄어들 것입니다. 왜냐하면 (a) 더 강력한 언어를 사용하면 아마도 많은 해커가 필요하지 않을 것이고 (b) 더 고급 언어로 작업하는 해커는 더 똑똑할 가능성이 높기 때문입니다. "표준" 기술로 인식되는 것을 사용하라는 많은 압력을 받지 않을 것이라는 말은 아닙니다.Viaweb(현재 Yahoo Store)에서 우리는 Lisp를 사용하여 VC와 잠재적 인수자들 사이에서 눈길을 끌었습니다.그러나 우리는 또한 Suns와 같은 "산업적 강점" 서버 대신 일반 Intel 상자를 서버로 사용하고, Windows NT와 같은 실제 상용 OS 대신 FreeBSD라는 당시 모호한 오픈 소스 Unix 변종을 사용하고, 현재는 아무도 기억하지 못하는 SET라는 전자 상거래 표준을 무시하는 등의 이유로 눈썹을 높였습니다. 양복이 귀하를 위해 기술적 결정을 내리도록 할 수는 없습니다.우리가 Lisp를 사용했다는 사실이 일부 잠재적인 인수자들에게 경고를 줬나요?약간은 있지만 Lisp를 사용하지 않았다면 그들이 우리를 사고 싶어하게 만드는 소프트웨어를 작성할 수 없었을 것입니다.그들에게 이상해 보이는 것이 사실은 원인과 결과였습니다. 스타트업을 시작한다면 제품을 디자인에 맞춰 디자인하지 마세요.

VC 또는 잠재적 인수자를 임대합니다.사용자가 만족할 수 있도록 제품을 디자인하세요.사용자를 이기면 다른 모든 것이 따라옵니다.그렇지 않으면 아무도 당신의 기술 선택이 얼마나 편안하고 정통적인지 신경 쓰지 않을 것입니다. 평균이 되는 비용 덜 강력한 언어를 사용하면 얼마나 많은 손실을 입을 수 있습니까?실제로 이에 대한 일부 데이터가 있습니다. 가장 편리한 전력 측정은 아마도 코드 크기일 것입니다.고급 언어의 요점은 더 큰 추상화를 제공하는 것입니다. 즉, 더 큰 벽돌을 제공하므로 주어진 크기의 벽을 만드는 데 많은 벽돌이 필요하지 않습니다.따라서 언어가 강력할수록 프로그램은 더 짧아집니다(물론 문자뿐만 아니라 개별 요소에서도). 더 강력한 언어를 사용하면 어떻게 더 짧은 프로그램을 작성할 수 있습니까?언어에 따라 사용할 수 있는 한 가지 기술은 상향식 프로그래밍입니다.단순히 기본 언어로 애플리케이션을 작성하는 대신, 기본 언어 위에 자신과 같은 프로그램을 작성하기 위한 언어를 구축한 다음 그 언어로 프로그램을 작성합니다.결합된 코드는 전체 프로그램을 기본 언어로 작성한 경우보다 훨씬 짧을 수 있습니다. 실제로 이것이 대부분의 압축 알고리즘이 작동하는 방식입니다.상향식 프로그램은 대부분의 경우 언어 계층을 전혀 변경할 필요가 없기 때문에 수정하기가 더 쉬워야 합니다. 프로그램을 작성하는 데 걸리는 시간은 대부분 코드 길이에 따라 달라지므로 코드 크기가 중요합니다.다른 언어로 프로그램의 길이가 3배 길어지면 작성하는 데도 3배의 시간이 걸릴 것입니다. 그리고 더 많은 사람을 고용한다고 해서 이 문제를 해결할 수는 없습니다. 왜냐하면 특정 규모를 초과하면 신규 채용은 실제로 순 손실이기 때문입니다.Fred Brooks는 그의 유명한 책 The Mythical Man-Month에서 이 현상을 설명했고, 내가 본 모든 것은 그가 말한 것을 확증하는 경향이 있었습니다. 그렇다면 Lisp로 작성하면 프로그램이 얼마나 짧아지나요?예를 들어 Lisp와 C에 대해 제가 들은 대부분의 숫자는 약 7-10x였습니다.그런데 최근 New Architect 잡지에 ITA에 관한 기사를 보면 "Lisp 한 줄이 C 줄 20개를 대체할 수 있다"고 나와 있는데, 이 기사에는 ITA 회장의 말을 인용한 내용이 가득하니 이 숫자를 ITA에서 따온 것으로 추측됩니다.그렇다면 우리는 그것에 어느 정도 믿음을 둘 수 있습니다.ITA의 소프트웨어에는 Lisp뿐만 아니라 C, C++도 많이 포함되어 있으므로 경험을 바탕으로 말하고 있습니다. 내 추측으로는 이러한 배수가 일정하지도 않은 것 같습니다.내 생각에는 더 어려운 문제에 직면할 때나 더 똑똑한 프로그래머가 있을 때 그 수가 증가한다고 생각합니다.정말 훌륭한 해커는 더 나은 도구에서 더 많은 것을 짜낼 수 있습니다. 곡선의 하나의 데이터 포인트로서 어쨌든 ITA와 경쟁하고 C로 소프트웨어를 작성하기로 결정했다면 그들은 당신보다 20배 더 빠르게 소프트웨어를 개발할 수 있을 것입니다.새로운 기능을 개발하는 데 1년을 소비했다면 3주 이내에 해당 기능을 복제할 수 있습니다.반면에 그들이 새로운 것을 개발하는 데 3개월만 투자했다면 당신도 그것을 개발하는 데 5년이 걸릴 것입니다. 그거 알아요?이것이 최선의 시나리오입니다.코드 크기 비율에 대해 이야기할 때 실제로 더 약한 언어로 프로그램을 작성할 수 있다고 암시적으로 가정하는 것입니다.하지만 실제로 프로그래머가 할 수 있는 일에는 한계가 있습니다.너무 낮은 수준의 언어로 어려운 문제를 해결하려고 하면 한꺼번에 머릿속에 담아둘 것이 너무 많은 지점에 도달하게 됩니다. 따라서 ITA의 가상 경쟁자가 ITA가 Lisp에서 3개월 안에 작성할 수 있는 내용을 복제하는 데 5년이 걸린다고 말하면 아무 문제가 없으면 5년이 걸린다는 뜻입니다.사실, 대부분의 회사에서 일이 돌아가는 방식으로는 5년이 걸리는 개발 프로젝트는 결코 완료되지 않을 가능성이 높습니다. 저는 이것이 극단적인 경우라는 것을 인정합니다.ITA의 해커들은 유난히 똑똑한 것 같고 C는 꽤 낮은 수준의 언어입니다.그러나 경쟁이 치열한 시장에서는 2~3대 1의 차이만으로도 항상 뒤처지게 될 것입니다. 레시피이것은 뾰족한 머리의 상사가 생각조차 하고 싶지 않은 종류의 가능성입니다.그래서 대부분은 그렇지 않습니다.왜냐하면, 알다시피, 그것이 다가올 때

게다가, 뾰족한 머리의 상사는 회사가 곤경에 처하더라도 아무도 그것이 그의 잘못이라는 것을 증명할 수 없는 한 신경 쓰지 않습니다.개인적으로 그에게 가장 안전한 계획은 무리의 중심에 가까이 붙어 있는 것입니다. 대규모 조직 내에서 이러한 접근 방식을 설명하는 데 사용되는 문구는 "업계 모범 사례"입니다.그 목적은 뾰족한 머리의 상사를 책임으로부터 보호하는 것입니다. 그가 "업계 최고의 관행"을 선택하고 회사가 패하더라도 그는 비난받을 수 없습니다.그가 선택한 것이 아니라 업계가 선택한 것입니다. 이 용어는 원래 회계 방법 등을 설명하는 데 사용되었다고 생각합니다.대략적인 의미는 이상한 짓을 하지 말라는 것입니다.그리고 회계에서는 아마도 좋은 생각일 것입니다."최첨단"과 "회계"라는 용어는 서로 잘 어울리지 않습니다.그러나 이 기준을 기술에 관한 결정에 적용하면 잘못된 답을 얻게 됩니다. 기술은 종종 최첨단이어야 합니다.프로그래밍 언어에서 Erann Gat가 지적했듯이 "업계 모범 사례"가 실제로 얻는 것은 최고가 아니라 단지 평균입니다.어떤 결정으로 인해 보다 공격적인 경쟁업체보다 훨씬 낮은 속도로 소프트웨어를 개발하게 된다면 "모범 사례"는 잘못된 이름입니다.여기에 제가 매우 가치 있다고 생각하는 두 가지 정보가 있습니다.사실 나는 내 경험을 통해 그것을 알고 있다.첫째, 언어의 힘은 다양합니다.둘째, 대부분의 관리자는 이를 의도적으로 무시합니다.그 사이에 이 두 가지 사실은 말 그대로 돈 버는 비법이다.ITA는 이 레시피가 실제로 실행되는 예입니다.소프트웨어 사업에서 승리하고 싶다면, 찾을 수 있는 가장 어려운 문제를 받아들이고, 얻을 수 있는 가장 강력한 언어를 사용하고, 경쟁사의 뾰족한 상사가 다시 나쁜 짓을 하기를 기다리세요.부록: 힘 프로그래밍 언어의 상대적인 힘에 대해 내가 의미하는 바를 설명하기 위해 다음 문제를 고려하십시오.우리는 누산기를 생성하는 함수를 작성하고 싶습니다. 숫자 n을 취하고 또 다른 숫자 i를 취하고 n을 i만큼 증가시켜 반환하는 함수를 반환합니다. (이것은 더하기가 아니라 증가합니다. 누산기는 누적되어야 합니다.) Common Lisp에서는 이것은 (defun foo (n) (lambda (i) (incf n i)))이고 Perl 5에서는 sub foo { my ($n) = @_;sub {$n += Shift} } Perl에서 수동으로 매개변수를 추출해야 하기 때문에 Lisp 버전보다 더 많은 요소가 있습니다. Smalltalk에서 코드는 Lisp foo보다 약간 더 깁니다. n |s|s := n.^[:나|s := s+i.] 일반적으로 어휘 변수는 작동하지만 매개변수에 할당할 수 없으므로 새 변수 s를 만들어야 합니다. Javascript에서는 명령문과 표현식 간의 구별을 유지하므로 예제가 약간 더 길어집니다. 따라서 값을 반환하려면 명시적인 return 문이 필요합니다. function foo(n) { return function (i) { return n += i } } (공평하게 말하면 Perl도 이 구별을 유지하지만 생략할 수 있게 하여 일반적인 Perl 방식으로 처리합니다.반환합니다.) Lisp/Perl/Smalltalk/Javascript 코드를 Python으로 변환하려고 하면 몇 가지 제한 사항이 발생합니다.Python은 어휘 변수를 완전히 지원하지 않기 때문에 n 값을 보유할 데이터 구조를 만들어야 합니다.Python에는 함수 데이터 유형이 있지만(본문이 단일 표현식인 경우를 제외하고) 이에 대한 리터럴 표현이 없으므로 반환할 명명된 함수를 만들어야 합니다.다음과 같이 끝납니다: def foo(n): s = [n] def bar(i): s[0] += i return s[0] return bar Python 사용자는 왜 def foo(n): return Lambda i: return n += i 또는 심지어 def foo(n):lambda i: n += i라고 쓸 수 없는지 합법적으로 질문할 수 있으며 내 추측으로는 언젠가는 그렇게 될 것입니다.(그러나 Python이 Lisp로 나머지 방식으로 발전할 때까지 기다리고 싶지 않다면 언제든지 그냥 할 수 있습니다...) OO 언어에서는 하나의 메소드와 필드로 클래스를 정의하여 둘러싸는 범위의 각 변수를 대체함으로써 제한된 범위 내에서 클로저( 둘러싸는 범위에 정의된 변수를 참조하는 함수)를 시뮬레이션할 수 있습니다.이것은 프로그래머가 일종의 코드를 수행하게 만듭니다.

이는 어휘 범위를 완벽하게 지원하는 언어에서 컴파일러가 수행할 수 있는 용해이며, 두 개 이상의 함수가 동일한 변수를 참조하는 경우 작동하지 않지만 이와 같은 간단한 경우에는 충분합니다. Python 전문가는 이것이 Python에서 문제를 해결하는 데 선호되는 방법이라는 데 동의하는 것 같습니다. def foo(n): class acc: def __init__(self, s): self.s = s def inc(self, i): self.s += i returnself.s return acc(n).inc 또는 class foo: def __init__(self, n): self.n = n def __call__(self, i): self.n += i return self.n Python 옹호자들이 내가 언어를 잘못 표현했다고 말하기를 원하지 않기 때문에 이것을 포함합니다. 그러나 둘 다 나에게는 첫 번째 버전보다 더 복잡해 보입니다.동일한 작업을 수행하여 어큐뮬레이터를 보관할 별도의 장소를 설정합니다.목록의 헤드가 아닌 객체의 필드일 뿐입니다.그리고 이러한 특별하고 예약된 필드 이름, 특히 __call__을 사용하는 것은 약간 해킹처럼 보입니다. Perl과 Python 사이의 경쟁에서 Python 해커의 주장은 Python이 Perl에 대한 더 우아한 대안이라고 주장하는 것 같습니다. 그러나 이 사례가 보여주는 것은 성능이 궁극적인 우아함이라는 것입니다. Perl 프로그램은 구문이 조금 더 보기 흉하더라도 더 간단합니다(요소가 더 적습니다). 다른 언어는 어떻습니까?이 강연에서 언급된 다른 언어(Fortran, C, C++, Java 및 Visual Basic)에서는 실제로 이 문제를 해결할 수 있는지 여부가 명확하지 않습니다.Ken Anderson은 다음 코드가 Java에서 얻을 수 있는 것과 거의 비슷하다고 말합니다. public interface Inttoint { public int call(int i);} 공개 정적 Inttoint foo(최종 int n) { return new Inttoint() { int s = n;공개 int 호출(int i) { s = s + i;반환 s;}};} 이는 정수에만 작동하기 때문에 사양에 미치지 못합니다.Java 해커들과 여러 번 이메일을 교환한 후에 앞의 예제처럼 동작하는 적절하게 다형성 버전을 작성하는 것은 정말 어색함과 불가능 사이의 어딘가에 있다고 말하고 싶습니다.누군가 글을 쓰고 싶다면 보고 싶은데 개인적으로 시간이 초과되었습니다. 물론 다른 언어에서는 이 문제를 해결할 수 없다는 말은 말 그대로 사실이 아닙니다.이 모든 언어가 Turing과 동등하다는 사실은 엄밀히 말하면 어떤 언어로든 어떤 프로그램이든 작성할 수 있다는 것을 의미합니다.그럼 어떻게 하시겠습니까?제한된 경우에는 덜 강력한 언어로 Lisp 인터프리터를 작성합니다. 농담처럼 들리지만 대규모 프로그래밍 프로젝트에서는 정도에 따라 너무 자주 발생하므로 이 현상에 대한 이름이 있습니다. Greenspun의 10번째 규칙: 충분히 복잡한 C 또는 Fortran 프로그램에는 Common Lisp의 절반에 대한 임시 비공식 지정 버그에 휩싸인 느린 구현이 포함되어 있습니다.어려운 문제를 해결하려고 할 때 문제는 충분히 강력한 언어를 사용할 것인지가 아니라 (a) 강력한 언어를 사용할 것인지, (b) 해당 언어에 대한 사실상의 통역사를 작성할 것인지, 아니면 (c) 자신이 해당 언어에 대한 인간 컴파일러가 될 것인지 여부입니다.우리는 Python 예제에서 이미 이런 일이 발생하기 시작했다는 것을 알 수 있습니다. 여기서 우리는 컴파일러가 어휘 변수를 구현하기 위해 생성하는 코드를 실제로 시뮬레이션하고 있습니다. 이 관행은 일반적일 뿐만 아니라 제도화되어 있습니다.예를 들어 객체지향 세계에서는 "패턴"에 대한 이야기를 많이 듣습니다.나는 이러한 패턴이 때로는 인간 컴파일러인 사례 (c)가 작동하고 있다는 증거가 아닌지 궁금합니다.내 프로그램에서 패턴을 볼 때 나는 그것이 문제의 징후라고 생각합니다.프로그램의 형태는 해결해야 할 문제만을 반영해야 합니다.코드의 다른 규칙성은 적어도 나에게는 충분히 강력하지 않은 추상화를 사용하고 있다는 신호입니다. 종종 작성해야 하는 일부 매크로의 확장을 손으로 생성하고 있다는 것입니다. 참고 IBM 704 CPU는 냉장고 크기 정도였지만 훨씬 더 무거웠습니다.CPU의 무게는 3150파운드였고, 4K RAM은 또 다른 4000파운드 무게의 별도 상자에 들어 있었습니다.가장 큰 가정용 냉장고 중 하나인 Sub-Zero 690의 무게는 656파운드입니다.Steve Russell은 또한 1962년에 최초의 (디지털) 컴퓨터 게임인 Spacewar를 썼습니다.

Lisp로 소프트웨어를 작성할 수 있도록 허락한다면 그에게 그것이 XML이라고 말해볼 수도 있습니다.다음은 다른 Lisp 방언의 누산기 생성기입니다. Scheme: (define (foo n) (lambda (i) (set! n (+ n i)) n)) Goo: (df foo (n) (op incf n _))) Arc: (def foo (n) [++ n _]) JPL의 "업계 모범 사례"에 대한 Erann Gat의 슬픈 이야기는 일반적으로 잘못 적용되는 이 문구를 해결하도록 영감을 주었습니다.Peter Norvig는 디자인 패턴의 23개 패턴 중 16개가 Lisp에서 "보이지 않거나 더 단순하다"는 사실을 발견했습니다.Ken Anderson, Trevor Blackwell, Erann Gat, Dan Giffin, Sarah Harlin, Jeremy Hylton, Robert Morris, Peter Norvig, Guy Steele 및 Anton van Straaten을 포함하여 다양한 언어에 대한 내 질문에 답변하고 초안을 읽어준 많은 사람들에게 감사드립니다.그들은 표현된 어떤 의견에 대해서도 책임을 지지 않습니다.관련 항목:많은 사람들이 이 강연에 응답했기 때문에 그들이 제기한 문제를 처리하기 위해 추가 페이지를 만들었습니다: Re: Revenge of the Nerds. 또한 LL1 메일링 리스트에서 광범위하고 종종 유용한 토론을 시작했습니다.특히 의미론적 압축에 대한 Anton van Straaten의 메일을 참조하세요. LL1의 메일 중 일부는 Succinctness is Power에서 언어 능력이라는 주제에 대해 더 깊이 들어가도록 유도했습니다. 누산기 생성기 벤치마크의 더 큰 표준 구현 세트가 자체 페이지에 함께 수집되어 있습니다. 일본어 번역, 스페인어 번역, 중국어 번역 Hackers & Painters에서 이 에세이와 14개의 다른 에세이를 찾을 수 있습니다.

---

## 원문 (Original Essay)

Want to start a startup? Get funded by Y Combinator. May 2002 "We were after the C++ programmers. We managed to drag a lot of them about halfway to Lisp."- Guy Steele, co-author of the Java spec In the software business there is an ongoing struggle between the pointy-headed academics, and another equally formidable force, the pointy-haired bosses. Everyone knows who the pointy-haired boss is, right? I think most people in the technology world not only recognize this cartoon character, but know the actual person in their company that he is modelled upon.The pointy-haired boss miraculously combines two qualities that are common by themselves, but rarely seen together: (a) he knows nothing whatsoever about technology, and (b) he has very strong opinions about it.Suppose, for example, you need to write a piece of software. The pointy-haired boss has no idea how this software has to work, and can't tell one programming language from another, and yet he knows what language you should write it in. Exactly. He thinks you should write it in Java.Why does he think this? Let's take a look inside the brain of the pointy-haired boss. What he's thinking is something like this. Java is a standard. I know it must be, because I read about it in the press all the time. Since it is a standard, I won't get in trouble for using it. And that also means there will always be lots of Java programmers, so if the programmers working for me now quit, as programmers working for me mysteriously always do, I can easily replace them.Well, this doesn't sound that unreasonable. But it's all based on one unspoken assumption, and that assumption turns out to be false. The pointy-haired boss believes that all programming languages are pretty much equivalent. If that were true, he would be right on target. If languages are all equivalent, sure, use whatever language everyone else is using.But all languages are not equivalent, and I think I can prove this to you without even getting into the differences between them. If you asked the pointy-haired boss in 1992 what language software should be written in, he would have answered with as little hesitation as he does today. Software should be written in C++. But if languages are all equivalent, why should the pointy-haired boss's opinion ever change? In fact, why should the developers of Java have even bothered to create a new language?Presumably, if you create a new language, it's because you think it's better in some way than what people already had. And in fact, Gosling makes it clear in the first Java white paper that Java was designed to fix some problems with C++. So there you have it: languages are not all equivalent. If you follow the trail through the pointy-haired boss's brain to Java and then back through Java's history to its origins, you end up holding an idea that contradicts the assumption you started with.So, who's right? James Gosling, or the pointy-haired boss? Not surprisingly, Gosling is right. Some languages are better, for certain problems, than others. And you know, that raises some interesting questions. Java was designed to be better, for certain problems, than C++. What problems? When is Java better and when is C++? Are there situations where other languages are better than either of them?Once you start considering this question, you have opened a real can of worms. If the pointy-haired boss had to think about the problem in its full complexity, it would make his brain explode. As long as he considers all languages equivalent, all he has to do is choose the one that seems to have the most momentum, and since that is more a question of fashion than technology, even he can probably get the right answer. But if languages vary, he suddenly has to solve two simultaneous equations, trying to find an optimal balance between two things he knows nothing about: the relative suitability of the twenty or so leading languages for the problem he needs to solve, and the odds of finding programmers, libraries, etc. for each. If that's what's on the other side of the door, it is no surprise that the pointy-haired boss doesn't want to open it.The disadvantage of believing that all programming languages are equivalent is that it's not true. But the advantage is that it makes your life a lot simpler. And I think that's the main reason the idea is so widespread. It is a comfortable idea.We know that Java must be pretty good, because it is the cool, new programming language. Or is it? If you look at the world of programming languages from a distance, it looks like Java is the latest thing. (From far enough away, all you can see is the large, flashing billboard paid for by Sun.) But if you look at this world up close, you find that there are degrees of coolness. Within the hacker subculture, there is another language called Perl that is considered a lot cooler than Java. Slashdot, for example, is generated by Perl. I don't think you would find those guys using Java Server Pages. But there is another, newer language, called Python, whose users tend to look down on Perl, and more waiting in the wings.If you look at these languages in order, Java, Perl, Python, you notice an interesting pattern. At least, you notice this pattern if you are a Lisp hacker. Each one is progressively more like Lisp. Python copies even features that many Lisp hackers consider to be mistakes. You could translate simple Lisp programs into Python line for line. It's 2002, and programming languages have almost caught up with 1958.Catching Up with MathWhat I mean is that Lisp was first discovered by John McCarthy in 1958, and popular programming languages are only now catching up with the ideas he developed then.Now, how could that be true? Isn't computer technology something that changes very rapidly? I mean, in 1958, computers were refrigerator-sized behemoths with the processing power of a wristwatch. How could any technology that old even be relevant, let alone superior to the latest developments?I'll tell you how. It's because Lisp was not really designed to be a programming language, at least not in the sense we mean today. What we mean by a programming language is something we use to tell a computer what to do. McCarthy did eventually intend to develop a programming language in this sense, but the Lisp that we actually ended up with was based on something separate that he did as a theoretical exercise-- an effort to define a more convenient alternative to the Turing Machine. As McCarthy said later, Another way to show that Lisp was neater than Turing machines was to write a universal Lisp function and show that it is briefer and more comprehensible than the description of a universal Turing machine. This was the Lisp function eval..., which computes the value of a Lisp expression.... Writing eval required inventing a notation representing Lisp functions as Lisp data, and such a notation was devised for the purposes of the paper with no thought that it would be used to express Lisp programs in practice. What happened next was that, some time in late 1958, Steve Russell, one of McCarthy's grad students, looked at this definition of eval and realized that if he translated it into machine language, the result would be a Lisp interpreter.This was a big surprise at the time. Here is what McCarthy said about it later in an interview: Steve Russell said, look, why don't I program this eval..., and I said to him, ho, ho, you're confusing theory with practice, this eval is intended for reading, not for computing. But he went ahead and did it. That is, he compiled the eval in my paper into [IBM] 704 machine code, fixing bugs, and then advertised this as a Lisp interpreter, which it certainly was. So at that point Lisp had essentially the form that it has today.... Suddenly, in a matter of weeks I think, McCarthy found his theoretical exercise transformed into an actual programming language-- and a more powerful one than he had intended.So the short explanation of why this 1950s language is not obsolete is that it was not technology but math, and math doesn't get stale. The right thing to compare Lisp to is not 1950s hardware, but, say, the Quicksort algorithm, which was discovered in 1960 and is still the fastest general-purpose sort.There is one other language still surviving from the 1950s, Fortran, and it represents the opposite approach to language design. Lisp was a piece of theory that unexpectedly got turned into a programming language. Fortran was developed intentionally as a programming language, but what we would now consider a very low-level one.Fortran I, the language that was developed in 1956, was a very different animal from present-day Fortran. Fortran I was pretty much assembly language with math. In some ways it was less powerful than more recent assembly languages; there were no subroutines, for example, only branches. Present-day Fortran is now arguably closer to Lisp than to Fortran I.Lisp and Fortran were the trunks of two separate evolutionary trees, one rooted in math and one rooted in machine architecture. These two trees have been converging ever since. Lisp started out powerful, and over the next twenty years got fast. So-called mainstream languages started out fast, and over the next forty years gradually got more powerful, until now the most advanced of them are fairly close to Lisp. Close, but they are still missing a few things....What Made Lisp DifferentWhen it was first developed, Lisp embodied nine new ideas. Some of these we now take for granted, others are only seen in more advanced languages, and two are still unique to Lisp. The nine ideas are, in order of their adoption by the mainstream, Conditionals. A conditional is an if-then-else construct. We take these for granted now, but Fortran I didn't have them. It had only a conditional goto closely based on the underlying machine instruction. A function type. In Lisp, functions are a data type just like integers or strings. They have a literal representation, can be stored in variables, can be passed as arguments, and so on. Recursion. Lisp was the first programming language to support it. Dynamic typing. In Lisp, all variables are effectively pointers. Values are what have types, not variables, and assigning or binding variables means copying pointers, not what they point to. Garbage-collection. Programs composed of expressions. Lisp programs are trees of expressions, each of which returns a value. This is in contrast to Fortran and most succeeding languages, which distinguish between expressions and statements.It was natural to have this distinction in Fortran I because you could not nest statements. And so while you needed expressions for math to work, there was no point in making anything else return a value, because there could not be anything waiting for it.This limitation went away with the arrival of block-structured languages, but by then it was too late. The distinction between expressions and statements was entrenched. It spread from Fortran into Algol and then to both their descendants. A symbol type. Symbols are effectively pointers to strings stored in a hash table. So you can test equality by comparing a pointer, instead of comparing each character. A notation for code using trees of symbols and constants. The whole language there all the time. There is no real distinction between read-time, compile-time, and runtime. You can compile or run code while reading, read or run code while compiling, and read or compile code at runtime.Running code at read-time lets users reprogram Lisp's syntax; running code at compile-time is the basis of macros; compiling at runtime is the basis of Lisp's use as an extension language in programs like Emacs; and reading at runtime enables programs to communicate using s-expressions, an idea recently reinvented as XML. When Lisp first appeared, these ideas were far removed from ordinary programming practice, which was dictated largely by the hardware available in the late 1950s. Over time, the default language, embodied in a succession of popular languages, has gradually evolved toward Lisp. Ideas 1-5 are now widespread. Number 6 is starting to appear in the mainstream. Python has a form of 7, though there doesn't seem to be any syntax for it.As for number 8, this may be the most interesting of the lot. Ideas 8 and 9 only became part of Lisp by accident, because Steve Russell implemented something McCarthy had never intended to be implemented. And yet these ideas turn out to be responsible for both Lisp's strange appearance and its most distinctive features. Lisp looks strange not so much because it has a strange syntax as because it has no syntax; you express programs directly in the parse trees that get built behind the scenes when other languages are parsed, and these trees are made of lists, which are Lisp data structures.Expressing the language in its own data structures turns out to be a very powerful feature. Ideas 8 and 9 together mean that you can write programs that write programs. That may sound like a bizarre idea, but it's an everyday thing in Lisp. The most common way to do it is with something called a macro.The term "macro" does not mean in Lisp what it means in other languages. A Lisp macro can be anything from an abbreviation to a compiler for a new language. If you want to really understand Lisp, or just expand your programming horizons, I would learn more about macros.Macros (in the Lisp sense) are still, as far as I know, unique to Lisp. This is partly because in order to have macros you probably have to make your language look as strange as Lisp. It may also be because if you do add that final increment of power, you can no longer claim to have invented a new language, but only a new dialect of Lisp.I mention this mostly as a joke, but it is quite true. If you define a language that has car, cdr, cons, quote, cond, atom, eq, and a notation for functions expressed as lists, then you can build all the rest of Lisp out of it. That is in fact the defining quality of Lisp: it was in order to make this so that McCarthy gave Lisp the shape it has.Where Languages MatterSo suppose Lisp does represent a kind of limit that mainstream languages are approaching asymptotically-- does that mean you should actually use it to write software? How much do you lose by using a less powerful language? Isn't it wiser, sometimes, not to be at the very edge of innovation? And isn't popularity to some extent its own justification? Isn't the pointy-haired boss right, for example, to want to use a language for which he can easily hire programmers?There are, of course, projects where the choice of programming language doesn't matter much. As a rule, the more demanding the application, the more leverage you get from using a powerful language. But plenty of projects are not demanding at all. Most programming probably consists of writing little glue programs, and for little glue programs you can use any language that you're already familiar with and that has good libraries for whatever you need to do. If you just need to feed data from one Windows app to another, sure, use Visual Basic.You can write little glue programs in Lisp too (I use it as a desktop calculator), but the biggest win for languages like Lisp is at the other end of the spectrum, where you need to write sophisticated programs to solve hard problems in the face of fierce competition. A good example is the airline fare search program that ITA Software licenses to Orbitz. These guys entered a market already dominated by two big, entrenched competitors, Travelocity and Expedia, and seem to have just humiliated them technologically.The core of ITA's application is a 200,000 line Common Lisp program that searches many orders of magnitude more possibilities than their competitors, who apparently are still using mainframe-era programming techniques. (Though ITA is also in a sense using a mainframe-era programming language.) I have never seen any of ITA's code, but according to one of their top hackers they use a lot of macros, and I am not surprised to hear it.Centripetal ForcesI'm not saying there is no cost to using uncommon technologies. The pointy-haired boss is not completely mistaken to worry about this. But because he doesn't understand the risks, he tends to magnify them.I can think of three problems that could arise from using less common languages. Your programs might not work well with programs written in other languages. You might have fewer libraries at your disposal. And you might have trouble hiring programmers.How much of a problem is each of these? The importance of the first varies depending on whether you have control over the whole system. If you're writing software that has to run on a remote user's machine on top of a buggy, closed operating system (I mention no names), there may be advantages to writing your application in the same language as the OS. But if you control the whole system and have the source code of all the parts, as ITA presumably does, you can use whatever languages you want. If any incompatibility arises, you can fix it yourself.In server-based applications you can get away with using the most advanced technologies, and I think this is the main cause of what Jonathan Erickson calls the "programming language renaissance." This is why we even hear about new languages like Perl and Python. We're not hearing about these languages because people are using them to write Windows apps, but because people are using them on servers. And as software shifts off the desktop and onto servers (a future even Microsoft seems resigned to), there will be less and less pressure to use middle-of-the-road technologies.As for libraries, their importance also depends on the application. For less demanding problems, the availability of libraries can outweigh the intrinsic power of the language. Where is the breakeven point? Hard to say exactly, but wherever it is, it is short of anything you'd be likely to call an application. If a company considers itself to be in the software business, and they're writing an application that will be one of their products, then it will probably involve several hackers and take at least six months to write. In a project of that size, powerful languages probably start to outweigh the convenience of pre-existing libraries.The third worry of the pointy-haired boss, the difficulty of hiring programmers, I think is a red herring. How many hackers do you need to hire, after all? Surely by now we all know that software is best developed by teams of less than ten people. And you shouldn't have trouble hiring hackers on that scale for any language anyone has ever heard of. If you can't find ten Lisp hackers, then your company is probably based in the wrong city for developing software.In fact, choosing a more powerful language probably decreases the size of the team you need, because (a) if you use a more powerful language you probably won't need as many hackers, and (b) hackers who work in more advanced languages are likely to be smarter.I'm not saying that you won't get a lot of pressure to use what are perceived as "standard" technologies. At Viaweb (now Yahoo Store), we raised some eyebrows among VCs and potential acquirers by using Lisp. But we also raised eyebrows by using generic Intel boxes as servers instead of "industrial strength" servers like Suns, for using a then-obscure open-source Unix variant called FreeBSD instead of a real commercial OS like Windows NT, for ignoring a supposed e-commerce standard called SET that no one now even remembers, and so on.You can't let the suits make technical decisions for you. Did it alarm some potential acquirers that we used Lisp? Some, slightly, but if we hadn't used Lisp, we wouldn't have been able to write the software that made them want to buy us. What seemed like an anomaly to them was in fact cause and effect.If you start a startup, don't design your product to please VCs or potential acquirers. Design your product to please the users. If you win the users, everything else will follow. And if you don't, no one will care how comfortingly orthodox your technology choices were.The Cost of Being AverageHow much do you lose by using a less powerful language? There is actually some data out there about that.The most convenient measure of power is probably code size. The point of high-level languages is to give you bigger abstractions-- bigger bricks, as it were, so you don't need as many to build a wall of a given size. So the more powerful the language, the shorter the program (not simply in characters, of course, but in distinct elements).How does a more powerful language enable you to write shorter programs? One technique you can use, if the language will let you, is something called bottom-up programming. Instead of simply writing your application in the base language, you build on top of the base language a language for writing programs like yours, then write your program in it. The combined code can be much shorter than if you had written your whole program in the base language-- indeed, this is how most compression algorithms work. A bottom-up program should be easier to modify as well, because in many cases the language layer won't have to change at all.Code size is important, because the time it takes to write a program depends mostly on its length. If your program would be three times as long in another language, it will take three times as long to write-- and you can't get around this by hiring more people, because beyond a certain size new hires are actually a net lose. Fred Brooks described this phenomenon in his famous book The Mythical Man-Month, and everything I've seen has tended to confirm what he said.So how much shorter are your programs if you write them in Lisp? Most of the numbers I've heard for Lisp versus C, for example, have been around 7-10x. But a recent article about ITA in New Architect magazine said that "one line of Lisp can replace 20 lines of C," and since this article was full of quotes from ITA's president, I assume they got this number from ITA. If so then we can put some faith in it; ITA's software includes a lot of C and C++ as well as Lisp, so they are speaking from experience.My guess is that these multiples aren't even constant. I think they increase when you face harder problems and also when you have smarter programmers. A really good hacker can squeeze more out of better tools.As one data point on the curve, at any rate, if you were to compete with ITA and chose to write your software in C, they would be able to develop software twenty times faster than you. If you spent a year on a new feature, they'd be able to duplicate it in less than three weeks. Whereas if they spent just three months developing something new, it would be five years before you had it too.And you know what? That's the best-case scenario. When you talk about code-size ratios, you're implicitly assuming that you can actually write the program in the weaker language. But in fact there are limits on what programmers can do. If you're trying to solve a hard problem with a language that's too low-level, you reach a point where there is just too much to keep in your head at once.So when I say it would take ITA's imaginary competitor five years to duplicate something ITA could write in Lisp in three months, I mean five years if nothing goes wrong. In fact, the way things work in most companies, any development project that would take five years is likely never to get finished at all.I admit this is an extreme case. ITA's hackers seem to be unusually smart, and C is a pretty low-level language. But in a competitive market, even a differential of two or three to one would be enough to guarantee that you'd always be behind.A RecipeThis is the kind of possibility that the pointy-haired boss doesn't even want to think about. And so most of them don't. Because, you know, when it comes down to it, the pointy-haired boss doesn't mind if his company gets their ass kicked, so long as no one can prove it's his fault. The safest plan for him personally is to stick close to the center of the herd.Within large organizations, the phrase used to describe this approach is "industry best practice." Its purpose is to shield the pointy-haired boss from responsibility: if he chooses something that is "industry best practice," and the company loses, he can't be blamed. He didn't choose, the industry did.I believe this term was originally used to describe accounting methods and so on. What it means, roughly, is don't do anything weird. And in accounting that's probably a good idea. The terms "cutting-edge" and "accounting" do not sound good together. But when you import this criterion into decisions about technology, you start to get the wrong answers.Technology often should be cutting-edge. In programming languages, as Erann Gat has pointed out, what "industry best practice" actually gets you is not the best, but merely the average. When a decision causes you to develop software at a fraction of the rate of more aggressive competitors, "best practice" is a misnomer. So here we have two pieces of information that I think are very valuable. In fact, I know it from my own experience. Number 1, languages vary in power. Number 2, most managers deliberately ignore this. Between them, these two facts are literally a recipe for making money. ITA is an example of this recipe in action. If you want to win in a software business, just take on the hardest problem you can find, use the most powerful language you can get, and wait for your competitors' pointy-haired bosses to revert to the mean. Appendix: PowerAs an illustration of what I mean about the relative power of programming languages, consider the following problem. We want to write a function that generates accumulators-- a function that takes a number n, and returns a function that takes another number i and returns n incremented by i.(That's incremented by, not plus. An accumulator has to accumulate.)In Common Lisp this would be (defun foo (n) (lambda (i) (incf n i))) and in Perl 5, sub foo { my ($n) = @_; sub {$n += shift} } which has more elements than the Lisp version because you have to extract parameters manually in Perl.In Smalltalk the code is slightly longer than in Lisp foo: n |s| s := n. ^[:i| s := s+i. ] because although in general lexical variables work, you can't do an assignment to a parameter, so you have to create a new variable s.In Javascript the example is, again, slightly longer, because Javascript retains the distinction between statements and expressions, so you need explicit return statements to return values: function foo(n) { return function (i) { return n += i } } (To be fair, Perl also retains this distinction, but deals with it in typical Perl fashion by letting you omit returns.)If you try to translate the Lisp/Perl/Smalltalk/Javascript code into Python you run into some limitations. Because Python doesn't fully support lexical variables, you have to create a data structure to hold the value of n. And although Python does have a function data type, there is no literal representation for one (unless the body is only a single expression) so you need to create a named function to return. This is what you end up with: def foo(n): s = [n] def bar(i): s[0] += i return s[0] return bar Python users might legitimately ask why they can't just write def foo(n): return lambda i: return n += i or even def foo(n): lambda i: n += i and my guess is that they probably will, one day. (But if they don't want to wait for Python to evolve the rest of the way into Lisp, they could always just...) In OO languages, you can, to a limited extent, simulate a closure (a function that refers to variables defined in enclosing scopes) by defining a class with one method and a field to replace each variable from an enclosing scope. This makes the programmer do the kind of code analysis that would be done by the compiler in a language with full support for lexical scope, and it won't work if more than one function refers to the same variable, but it is enough in simple cases like this.Python experts seem to agree that this is the preferred way to solve the problem in Python, writing either def foo(n): class acc: def __init__(self, s): self.s = s def inc(self, i): self.s += i return self.s return acc(n).inc or class foo: def __init__(self, n): self.n = n def __call__(self, i): self.n += i return self.n I include these because I wouldn't want Python advocates to say I was misrepresenting the language, but both seem to me more complex than the first version. You're doing the same thing, setting up a separate place to hold the accumulator; it's just a field in an object instead of the head of a list. And the use of these special, reserved field names, especially __call__, seems a bit of a hack.In the rivalry between Perl and Python, the claim of the Python hackers seems to be that that Python is a more elegant alternative to Perl, but what this case shows is that power is the ultimate elegance: the Perl program is simpler (has fewer elements), even if the syntax is a bit uglier.How about other languages? In the other languages mentioned in this talk-- Fortran, C, C++, Java, and Visual Basic-- it is not clear whether you can actually solve this problem. Ken Anderson says that the following code is about as close as you can get in Java: public interface Inttoint { public int call(int i); } public static Inttoint foo(final int n) { return new Inttoint() { int s = n; public int call(int i) { s = s + i; return s; }}; } This falls short of the spec because it only works for integers. After many email exchanges with Java hackers, I would say that writing a properly polymorphic version that behaves like the preceding examples is somewhere between damned awkward and impossible. If anyone wants to write one I'd be very curious to see it, but I personally have timed out.It's not literally true that you can't solve this problem in other languages, of course. The fact that all these languages are Turing-equivalent means that, strictly speaking, you can write any program in any of them. So how would you do it? In the limit case, by writing a Lisp interpreter in the less powerful language.That sounds like a joke, but it happens so often to varying degrees in large programming projects that there is a name for the phenomenon, Greenspun's Tenth Rule: Any sufficiently complicated C or Fortran program contains an ad hoc informally-specified bug-ridden slow implementation of half of Common Lisp. If you try to solve a hard problem, the question is not whether you will use a powerful enough language, but whether you will (a) use a powerful language, (b) write a de facto interpreter for one, or (c) yourself become a human compiler for one. We see this already begining to happen in the Python example, where we are in effect simulating the code that a compiler would generate to implement a lexical variable.This practice is not only common, but institutionalized. For example, in the OO world you hear a good deal about "patterns". I wonder if these patterns are not sometimes evidence of case (c), the human compiler, at work. When I see patterns in my programs, I consider it a sign of trouble. The shape of a program should reflect only the problem it needs to solve. Any other regularity in the code is a sign, to me at least, that I'm using abstractions that aren't powerful enough-- often that I'm generating by hand the expansions of some macro that I need to write.Notes The IBM 704 CPU was about the size of a refrigerator, but a lot heavier. The CPU weighed 3150 pounds, and the 4K of RAM was in a separate box weighing another 4000 pounds. The Sub-Zero 690, one of the largest household refrigerators, weighs 656 pounds. Steve Russell also wrote the first (digital) computer game, Spacewar, in 1962. If you want to trick a pointy-haired boss into letting you write software in Lisp, you could try telling him it's XML. Here is the accumulator generator in other Lisp dialects: Scheme: (define (foo n) (lambda (i) (set! n (+ n i)) n)) Goo: (df foo (n) (op incf n _))) Arc: (def foo (n) [++ n _]) Erann Gat's sad tale about "industry best practice" at JPL inspired me to address this generally misapplied phrase. Peter Norvig found that 16 of the 23 patterns in Design Patterns were "invisible or simpler" in Lisp. Thanks to the many people who answered my questions about various languages and/or read drafts of this, including Ken Anderson, Trevor Blackwell, Erann Gat, Dan Giffin, Sarah Harlin, Jeremy Hylton, Robert Morris, Peter Norvig, Guy Steele, and Anton van Straaten. They bear no blame for any opinions expressed. Related:Many people have responded to this talk, so I have set up an additional page to deal with the issues they have raised: Re: Revenge of the Nerds.It also set off an extensive and often useful discussion on the LL1 mailing list. See particularly the mail by Anton van Straaten on semantic compression.Some of the mail on LL1 led me to try to go deeper into the subject of language power in Succinctness is Power.A larger set of canonical implementations of the accumulator generator benchmark are collected together on their own page.Japanese Translation, Spanish Translation, Chinese Translation You'll find this essay and 14 others in Hackers & Painters.

---

_분석일: 2025. 11. 29._
_수집일: 2025. 11. 28._
