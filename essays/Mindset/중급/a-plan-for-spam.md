# A Plan for Spam
**카테고리**: Mindset
**난이도**: 중급
**출판일**: N/A
**원문**: https://paulgraham.com/spam.html
---
## 요약 (Summary)

🎯 스팸을 없애는 계획은 무엇일까요?

✨ 핵심 내용 요약

2000년대 초 스팸 메일이 폭발했습니다. Paul Graham의 해결책: **통계 기반 필터**.

기존 필터는 규칙 기반이었습니다: "viagra 포함 → 스팸". 하지만 스팸 발송자가 "v1agra"로 우회했습니다. Graham의 아이디어: 규칙 대신 통계를 쓰세요. 각 단어의 "스팸 확률"을 계산합니다. 여러 단어를 조합해서 전체 확률을 계산합니다. 99% 이상이면 스팸입니다. 혁신적인 점: **학습합니다**. 새로운 스팸이 나와도 자동으로 적응합니다. 이 아이디어가 나중에 Gmail의 스팸 필터가 됩니다. 스타트업 교훈: 복잡한 규칙보다 간단한 학습이 낫습니다.

**핵심 포인트**
• 규칙 기반보다 통계 기반이 낫습니다
• 학습하는 시스템이 강력합니다
• 간단한 아이디어가 세상을 바꿉니다

🚀 오늘 바로 실천해볼 한 가지
복잡한 규칙을 만들기보다, 데이터에서 학습하는 시스템을 만드세요.

---

## 한국어 번역 (Korean Translation)

물건 만들기를 좋아하시나요?해커 뉴스를 사용해 보세요.2002년 8월(이 기사에서는 Arc를 연습하기 위해 만든 스팸 방지 웹 기반 메일 리더에 사용되는 스팸 필터링 기술에 대해 설명합니다. 향상된 알고리즘은 Better Bayesian Filtering에 설명되어 있습니다.) 스팸을 차단하는 것이 가능하고 콘텐츠 기반 필터가 이를 수행하는 방법이라고 생각합니다.스패머의 아킬레스건은 메시지입니다.그들은 당신이 설정한 다른 장벽을 우회할 수 있습니다.적어도 지금까지는 그렇습니다.하지만 그것이 무엇이든 간에 그들은 메시지를 전달해야 합니다.메시지를 인식하는 소프트웨어를 작성할 수 있다면 이를 피할 수 있는 방법은 없습니다._ _ _수신자에게 스팸은 쉽게 인식될 수 있습니다.메일을 읽고 스팸을 삭제하도록 누군가를 고용했다면 그들은 그 일을 하는 데 거의 어려움을 겪지 않을 것입니다.이 과정을 자동화하려면 AI가 없으면 얼마나 해야 할까요? 상당히 간단한 알고리즘으로 문제를 해결할 수 있을 것 같습니다.실제로 저는 개별 단어의 스팸 가능성에 대한 베이지안 조합만을 사용하여 오늘날의 스팸을 적절하게 필터링할 수 있다는 사실을 발견했습니다.아래에 설명된 대로 약간 수정된 베이지안 필터를 사용하여 이제 스팸 1000개당 5개 미만을 놓치고 거짓 긍정은 0개입니다. 통계적 접근 방식은 일반적으로 사람들이 스팸 필터를 작성할 때 시도하는 첫 번째 접근 방식이 아닙니다.대부분의 해커의 첫 번째 본능은 스팸의 개별 속성을 인식하는 소프트웨어를 작성하는 것입니다.스팸을 보면 "Dear Friend"로 시작하거나 제목 줄이 모두 대문자이고 느낌표 8개로 끝나는 메일을 나에게 보내려는 이 사람들의 담대함을 생각하게 됩니다.한 줄의 코드로 그런 것들을 필터링할 수 있습니다. 그렇게 하면 처음에는 작동합니다.몇 가지 간단한 규칙을 사용하면 수신되는 스팸을 크게 줄일 수 있습니다.단순히 "클릭"이라는 단어만 검색하면 내 스팸 자료에 있는 이메일의 79.7%를 잡을 수 있으며 오탐률은 1.2%에 불과합니다. 저는 통계적 접근 방식을 시도하기 전에 개별 스팸 기능을 찾는 소프트웨어를 작성하는 데 약 6개월을 보냈습니다.내가 발견한 것은 스팸의 마지막 몇 퍼센트가 매우 어렵다는 것을 인식하고 필터를 더 엄격하게 만들수록 오탐지가 더 많아진다는 것입니다. 오탐지는 스팸으로 잘못 식별되는 무해한 이메일입니다.대부분의 사용자에게 합법적인 이메일을 놓치는 것은 스팸을 받는 것보다 훨씬 더 나쁩니다. 따라서 거짓 긍정을 생성하는 필터는 환자의 사망 위험을 안겨주는 여드름 치료제와 같습니다. 사용자가 스팸을 많이 받을수록 스팸 폴더에 있는 무해한 메일 하나를 발견할 가능성은 줄어듭니다.그리고 이상하게도 스팸 필터가 좋아질수록 잘못된 긍정이 더 위험해집니다. 왜냐하면 필터가 정말 좋으면 사용자는 자신이 발견한 모든 것을 무시할 가능성이 더 높기 때문입니다. 왜 그렇게 오랫동안 통계적 접근 방식을 피했는지 모르겠습니다.마치 스패머들과 일종의 경쟁 게임을 하는 것처럼 스스로 스팸 기능을 찾아내려는 노력에 중독되었기 때문인 것 같습니다.(해커가 아닌 사람들은 이것을 종종 깨닫지 못하지만 대부분의 해커들은 매우 경쟁적입니다.) 통계 분석을 시도했을 때 나는 그것이 이전보다 훨씬 더 영리하다는 것을 즉시 발견했습니다.물론 "virtumundo"나 "teens"와 같은 용어가 스팸을 나타내는 좋은 지표라는 사실도 발견되었습니다.그러나 "per", "FL" 및 "ff0000"이 스팸을 나타내는 좋은 지표라는 사실도 발견했습니다.실제로 "ff0000"(밝은 빨간색의 경우 html)은 포르노 용어만큼 스팸을 나타내는 좋은 지표임이 밝혀졌습니다._ _ _여기에 제가 통계 필터링을 수행하는 방법에 대한 간략한 설명이 있습니다.스팸 메일 모음 하나와 스팸이 아닌 메일 모음 하나로 시작합니다.현재 각 메시지에는 약 4000개의 메시지가 있습니다.나는 각 말뭉치에 있는 각 메시지의 헤더와 포함된 HTML 및 자바스크립트를 포함한 전체 텍스트를 검사합니다.나는 현재 영숫자 문자, 대시, 아포스트로피 및 달러 기호를 토큰의 일부로 간주하고 그 밖의 모든 것을 토큰 구분 기호로 간주합니다.(아마도 개선의 여지가 있을 것 같습니다.) 모두 숫자인 토큰을 무시하고, html 주석도 토큰 세파로 간주하지 않고 무시합니다.

rators. 각 말뭉치에서 각 토큰(현재 대소문자 무시)이 발생하는 횟수를 셉니다.이 단계에서는 각 말뭉치당 하나씩, 토큰을 발생 횟수에 매핑하는 두 개의 큰 해시 테이블이 생성됩니다. 다음으로 세 번째 해시 테이블을 생성합니다. 이번에는 각 토큰을 포함하는 이메일이 스팸일 확률에 매핑하고 다음과 같이 계산합니다. [1]: (let ((g (* 2 (or (gethash word good) 0))) (b (or (gethash word bad) 0))) (unless (< (+ g b) 5)(max .01 (min .99 (float (/ (min 1 (/ b nbad)) (+ (min 1 (/ g ngood)) (min 1 (/ b nbad)))))))) 여기서 word는 확률을 계산하는 토큰이고, good과 bad는 첫 번째 단계에서 만든 해시 테이블이고, ngood과 nbad는 각각 스팸이 아닌 메시지와 스팸 메시지의 수입니다. 이를 몇 가지 중요한 세부 정보를 표시하기 위한 코드로 설명했습니다.나는 거짓 긍정을 피하기 위해 확률을 약간 편향시키고 싶습니다. 시행 착오를 통해 모든 숫자를 두 배로 늘리는 것이 좋은 방법이라는 것을 알았습니다.이는 합법적인 이메일에 가끔 등장하는 단어와 거의 발생하지 않는 단어를 구별하는 데 도움이 됩니다.총 5번 이상 나타나는 단어만 고려합니다. (실제로는 두 배가 되기 때문에 스팸이 아닌 메일에서는 3번 발생하면 충분합니다.)그리고 한 코퍼스에서는 발생하지만 다른 코퍼스에서는 발생하지 않는 단어에 할당할 확률이 얼마인지에 대한 질문이 있습니다.이번에도 시행착오를 거쳐 .01과 .99를 선택했습니다.여기에서 조정할 여지가 있을 수 있지만 말뭉치가 커짐에 따라 그러한 조정은 어쨌든 자동으로 발생합니다. 특히 관찰력이 있는 사람은 발생 횟수를 계산할 목적으로 각 말뭉치를 하나의 긴 텍스트 스트림으로 간주하지만 스팸 확률을 계산할 때 제수로 결합된 길이가 아닌 각각의 이메일 수를 사용한다는 점을 주목하게 될 것입니다.이는 잘못된 긍정으로부터 보호하기 위해 또 다른 약간의 편향을 추가합니다. 새 메일이 도착하면 토큰으로 스캔되고 스팸 확률이 중립 0.5에서 얼마나 멀리 있는지에 따라 측정되는 가장 흥미로운 15개의 토큰을 사용하여 메일이 스팸일 확률을 계산합니다.probs가 15개의 개별 확률 목록인 경우 다음과 같이 결합된 확률을 계산합니다. (let ((prod (apply #'* probs))) (/ prod (+ prod (apply #'* (mapcar #'(lambda (x) (- 1 x)) probs)))) 실제로 발생하는 한 가지 질문은 본 적이 없는 단어, 즉 단어의 해시 테이블에 나타나지 않는 단어에 할당할 확률이 얼마인지입니다.확률.나는 시행착오를 통해 .4가 사용하기에 좋은 숫자라는 것을 다시 한번 발견했습니다.이전에 단어를 본 적이 없다면 아마도 상당히 순수할 것입니다.스팸 단어는 너무 익숙한 경향이 있습니다. 마지막 부록에 이 알고리즘을 실제 이메일에 적용한 예가 있습니다. 위의 알고리즘이 스팸일 확률이 0.9 이상일 경우 메일을 스팸으로 처리합니다.그러나 실제로는 이 임계값을 어디에 두는지는 별로 중요하지 않습니다. 왜냐하면 범위의 중간에 도달할 가능성이 거의 없기 때문입니다._ _ _통계적 접근 방식의 가장 큰 장점 중 하나는 너무 많은 스팸을 읽을 필요가 없다는 것입니다.지난 6개월 동안 저는 문자 그대로 수천 통의 스팸 메일을 읽었는데, 정말 사기를 저하시키는 내용이었습니다.Norbert Wiener는 노예와 경쟁하면 노예가 되는 것이며 스패머와 경쟁하는 것에도 비슷하게 굴욕적인 일이 있다고 말했습니다.개별 스팸 기능을 인식하려면 스패머의 마음 속으로 들어가려고 노력해야 하며 솔직히 저는 스패머의 마음 속에 가능한 한 적은 시간을 보내고 싶습니다. 그러나 베이지안 접근 방식의 진정한 장점은 물론 무엇을 측정하고 있는지 알 수 있다는 것입니다.SpamAssassin과 같은 기능 인식 필터는 이메일에 스팸 "점수"를 할당합니다.베이지안 접근 방식은 실제 확률을 할당합니다."점수"의 문제점은 그것이 무엇을 의미하는지 아무도 모른다는 것입니다.사용자는 그것이 무엇을 의미하는지 모르지만 더 나쁜 것은 필터 개발자도 마찬가지입니다."sex"라는 단어가 포함된 이메일은 몇 점을 받아야 합니까?물론 확률은 틀릴 수도 있지만, 그럴 확률은 거의 없습니다.

그것이 무엇을 의미하는지, 또는 그것을 계산하기 위해 증거를 어떻게 결합해야 하는지에 대한 모호함.내 말뭉치에 따르면 "sex"는 포함된 이메일이 스팸일 확률이 .97임을 나타내고 "sexy"는 .99 확률을 나타냅니다.그리고 베이즈의 법칙 역시 마찬가지로 명확하게 두 단어가 모두 포함된 이메일은 다른 증거가 없을 경우 스팸일 확률이 99.97%라고 말합니다. 확률을 측정하기 때문에 베이지안 접근 방식은 이메일에 있는 좋은 증거와 나쁜 증거를 모두 고려합니다.스팸에서 불균형적으로 드물게 나타나는 단어(예: "그래도", "오늘 밤" 또는 "명백히")는 "구독 취소" 및 "선택"과 같은 나쁜 단어가 확률을 높이는 데 기여하는 만큼 확률을 줄이는 데 기여합니다.따라서 "섹스"라는 단어가 포함된 무고한 이메일에는 스팸 태그가 지정되지 않습니다. 물론 이상적으로는 각 사용자에 대해 개별적으로 확률을 계산해야 합니다.나는 "Lisp"라는 단어가 포함된 이메일을 많이 받았는데, (지금까지) 그런 단어가 포함된 스팸은 없습니다.그래서 그런 단어는 나에게 메일을 보내는 일종의 비밀번호와도 같습니다.이전 스팸 필터링 소프트웨어에서는 사용자가 이러한 단어 목록을 설정하면 해당 단어가 포함된 메일이 자동으로 필터를 통과했습니다.내 목록에는 "Lisp"와 같은 단어와 내 우편번호도 넣었습니다. 그렇지 않으면 스팸처럼 들리는 온라인 주문 영수증이 전달됩니다.나는 내가 매우 영리하다고 생각했지만 베이지안 필터가 나에게 같은 일을 한다는 것을 알았고, 게다가 내가 생각하지 못한 많은 단어를 발견했다는 것을 발견했습니다. 처음에 우리 필터가 0개의 거짓 긍정으로 1000개당 5개 미만의 스팸을 통과한다고 말했을 때, 나는 내 메일 모음을 기반으로 내 메일을 필터링하는 것에 대해 이야기하고 있습니다.그러나 이 숫자는 내가 옹호하는 접근 방식이기 때문에 오해의 소지가 없습니다. 즉, 수신하는 스팸 메일과 스팸이 아닌 메일을 기준으로 각 사용자의 메일을 필터링하는 것입니다.기본적으로 각 사용자에게는 일반 삭제와 스팸으로 삭제라는 두 개의 삭제 버튼이 있어야 합니다.스팸으로 삭제된 모든 항목은 스팸 자료로 들어가고 그 밖의 모든 내용은 스팸이 아닌 자료로 들어갑니다. 시드 필터로 사용자를 시작할 수 있지만 궁극적으로 각 사용자는 자신이 받은 실제 메일을 기반으로 한 단어별 확률을 가져야 합니다.이는 (a) 필터를 더욱 효과적으로 만들고, (b) 각 사용자가 스팸에 대한 정확한 정의를 스스로 결정할 수 있게 하며, (c) 무엇보다도 스패머가 메일을 조정하여 필터를 통과하는 것을 어렵게 만듭니다.필터의 대부분이 개별 데이터베이스에 있는 경우 시드 필터를 통과하도록 스팸을 조정하는 것만으로는 개별 사용자의 다양하고 훨씬 더 훈련된 필터를 얼마나 잘 통과할지 보장할 수 없습니다. 콘텐츠 기반 스팸 필터링은 필터링 없이 메일을 수락할 수 있는 보낸 사람 목록인 화이트리스트와 결합되는 경우가 많습니다.이러한 화이트리스트를 작성하는 쉬운 방법 중 하나는 사용자가 메일을 보낸 모든 주소 목록을 유지하는 것입니다.메일 리더에 스팸으로 삭제 버튼이 있는 경우 사용자가 삭제한 모든 이메일의 보낸 사람 주소를 일반 휴지통으로 추가할 수도 있습니다. 저는 화이트리스트를 옹호하지만 필터링을 개선하는 방법보다는 계산을 절약하는 방법에 더 가깝습니다.나는 화이트리스트를 사용하면 필터링이 더 쉬워질 것이라고 생각했습니다. 왜냐하면 한 번도 들어본 적이 없는 사람의 이메일만 필터링하면 되고, 처음으로 메일을 보내는 사람은 관습에 따라 말할 수 있는 내용이 제한되기 때문입니다.당신이 이미 아는 사람이 당신에게 섹스에 관해 이야기하는 이메일을 보낼 수도 있지만, 처음으로 당신에게 메일을 보내는 사람은 그렇지 않을 것입니다.문제는 사람들이 하나 이상의 이메일 주소를 가질 수 있으므로 새 보낸 사람 주소가 보낸 사람이 처음으로 당신에게 편지를 쓴다는 것을 보장하지 않는다는 것입니다.오랜 친구(특히 해커인 경우)가 갑자기 새로운 보낸 사람 주소가 포함된 이메일을 보내는 것은 드문 일이 아니므로 알 수 없는 주소에서 보낸 메일을 특히 엄격하게 필터링하여 오탐의 위험을 피할 수 있습니다. 하지만 어떤 의미에서 내 필터는 전체 me를 기반으로 하기 때문에 일종의 화이트리스트(및 블랙리스트)를 구현합니다.

헤더를 포함한 현자.그래서 그 정도까지 그들은 신뢰할 수 있는 발신자의 이메일 주소와 심지어 그 사람에게서 나에게 메일이 전달되는 경로까지 "알고 있습니다".그리고 그들은 서버 이름, 메일러 버전, 프로토콜을 포함하여 스팸에 대해서도 똑같이 알고 있습니다._ _ _현재 스팸 필터링 속도를 유지할 수 있다고 생각했다면 이 문제가 해결되었다고 생각합니다.하지만 스팸은 진화하기 때문에 대부분의 최신 스팸을 필터링할 수 있다는 것은 큰 의미가 없습니다.실제로 지금까지 대부분의 스팸 방지 기술은 새롭고 저항력이 있는 버그를 생성하는 것 외에는 아무 것도 하지 않는 살충제와 같았습니다. 베이지안 필터는 스팸과 함께 진화하기 때문에 저는 베이지안 필터에 대해 더 희망적입니다.따라서 스패머가 개별 단어를 기반으로 하는 단순한 스팸 필터를 회피하기 위해 "cock" 대신 "c0ck"를 사용하기 시작하면 베이지안 필터가 자동으로 이를 알아차립니다.실제로 "c0ck"은 "cock"보다 훨씬 더 끔찍한 증거이며 베이지안 필터는 얼마나 더 많은 증거를 정확하게 알고 있습니다. 그럼에도 불구하고 스팸 필터링 계획을 제안하는 사람은 다음 질문에 답할 수 있어야 합니다. 스패머가 귀하가 무엇을 하고 있는지 정확히 알고 있다면 얼마나 잘 지나갈 수 있습니까?예를 들어, 체크섬 기반 스팸 필터링이 심각한 장애가 된다면 스패머는 메시지 본문을 생성하기 위해 mad-lib 기술로 전환할 것입니다. 베이지안 필터를 이기기 위해서는 스패머가 이메일을 고유하게 만들거나 개별적인 나쁜 단어 사용을 중단하는 것만으로는 충분하지 않습니다.그들은 자신의 우편물을 일반 우편물과 구별할 수 없도록 만들어야 합니다.그리고 이것은 그들을 심각하게 제약할 것이라고 생각합니다.스팸은 대부분 판매 홍보이므로 일반 메일이 모두 판매 홍보가 아닌 이상 스팸은 필연적으로 다른 성격을 갖게 됩니다.물론 스패머는 전체 인프라를 변경해야 합니다(그리고 계속 변경해야 합니다). 그렇지 않으면 메시지 본문에 어떤 작업을 하든 베이지안 필터에 헤더가 이전과 마찬가지로 좋지 않게 보일 것이기 때문입니다.나는 스패머가 헤더를 순진해 보이게 만드는 것이 얼마나 어려운지 알기 위해 사용하는 인프라에 대해 충분히 알지 못합니다. 하지만 내 생각에는 메시지를 순진해 보이게 만드는 것보다 훨씬 더 어려울 것입니다. 그들이 헤더 문제를 해결할 수 있다고 가정하면 미래의 스팸은 아마도 다음과 같을 것입니다. 안녕하세요.다음을 확인해야 한다고 생각했습니다. http://www.27meg.com/foo 왜냐하면 콘텐츠 기반 필터링이 스패머 방을 떠날 만큼 판매 홍보에 관한 것이기 때문입니다.(실제로 이메일의 다른 모든 것이 중립적이라면 스팸 가능성은 URL에 달려 있고 이를 중립적으로 보이도록 하려면 약간의 노력이 필요하기 때문에 과거 필터를 얻는 것조차 어려울 것입니다.) 스패머는 자신의 신원을 숨기려고 시도하지 않는 소위 선택 목록을 운영하는 기업부터 포르노 사이트를 홍보하는 스팸을 보내기 위해 메일 서버를 하이재킹하는 사람까지 다양합니다.필터링을 사용하여 위와 같은 메일로 옵션을 줄인다면 스패머는 스펙트럼의 "합법적" 끝에 위치하게 됩니다.그들은 다양한 주 법률에 따라 스팸이 스팸이 아닌 이유와 "구독"을 취소하는 방법에 대한 상용구를 포함해야 한다고 생각합니다. 그런 종류의 텍스트는 쉽게 알아볼 수 있습니다. (나는 더 엄격한 법률이 스팸을 줄일 것이라고 믿는 것이 순진하다고 생각했습니다. 이제는 더 엄격한 법률이 스패머가 보내는 스팸의 양을 줄이지는 못하더라도 수신자가 실제로 보는 스팸의 양을 줄이는 필터링에 확실히 도움이 될 수 있다고 생각합니다.)스패머가 스팸을 만들면 필연적으로 스팸 발송자가 폐업하는 경향이 있습니다.사업이라는 단어는 기억해야 할 중요한 단어입니다.스팸 발송자는 사업가입니다.그들은 효과가 있기 때문에 스팸을 보냅니다.응답률이 엄청나게 낮음에도 불구하고(카탈로그 메일링의 경우 최대 15/100만, 대 카탈로그 메일링의 경우 3000) 비용은 사실상 아무것도 아니기 때문에 작동합니다.스팸을 삭제하는 데 1초를 소비하는 백만 명의 수신자마다 약 5주(man-week)가 소요되는 수신자 입장에서는 엄청난 비용이 들지만 스패머는 그 비용을 지불할 필요가 없습니다.Sendi

하지만 ng 스팸은 스패머에게 상당한 비용을 발생시킵니다.[2] 따라서 필터링을 통해 또는 스패머가 자신의 메시지를 희석하도록 필터를 사용하여 응답률을 낮출수록 더 적은 수의 기업에서 스팸을 보낼 가치가 있다고 생각하게 됩니다. 스패머가 판매 홍보와 같은 유형을 사용하는 이유는 응답률을 높이기 위한 것입니다.이는 스패머의 마음 속으로 들어가는 것보다 훨씬 더 역겨운 일일 수 있지만 스팸에 응답하는 사람의 마음 속을 잠깐 살펴보겠습니다.이 사람은 자신의 성적 관심에 대해 놀라울 정도로 잘 믿거나 깊이 부인합니다.두 경우 모두 스팸이 우리에게 혐오스럽거나 바보처럼 보이지만 그들에게는 흥미진진한 일입니다.스패머들은 흥미롭지 않다면 이런 말을 하지 않을 것입니다.그리고 "다음 사항을 확인해야 한다고 생각했습니다"는 현재 스패머가 말하는 것과 같이 스팸 수신자를 거의 끌어들이지 못할 것입니다.결과: 흥미진진한 판매 홍보 문구를 포함할 수 없으면 스팸은 마케팅 수단으로서의 효율성이 떨어지고 스팸을 사용하려는 기업의 수가 줄어듭니다. 이것이 결국 큰 승리입니다.나는 더 이상 스팸을 볼 필요가 없기 때문에 스팸 필터링 소프트웨어를 작성하기 시작했습니다.그러나 우리가 스팸을 충분히 필터링하면 스팸의 작동이 중단되고 스패머는 실제로 스팸 발송을 중단할 것입니다._ _ _소프트웨어에서 법률에 이르기까지 스팸을 퇴치하는 모든 접근 방식 중에서 베이지안 필터링이 가장 효과적인 단일 필터링이 될 것이라고 믿습니다.하지만 우리가 수행하는 스팸 방지 노력이 다양할수록 더 좋다고 생각합니다. 스패머를 제한하는 모든 조치가 필터링을 더 쉽게 만드는 경향이 있기 때문입니다.그리고 콘텐츠 기반 필터링의 세계에서도 여러 종류의 소프트웨어가 동시에 사용된다면 좋은 일이라고 생각합니다.필터가 다양할수록 스패머가 스팸을 조정하여 필터를 통과하기가 더 어려워집니다.부록: 필터링의 예여기에는 제가 이 글을 쓰는 동안 도착한 스팸의 예가 있습니다.이 스팸에서 가장 흥미로운 15개의 단어는 다음과 같습니다. qvp0045 indira mx-05 intimail $7500 freeyankeedom cdo bluefoxmedia jpg unsecured 플래티넘 3d0 qves 7c5 7c266675 이 단어는 전형적인 스팸의 전형적인 헤더와 메시지 본문의 내용을 혼합한 것입니다.또한 스팸의 일반적인 특징은 이러한 모든 단어가 내 데이터베이스에 있는 스팸 확률이 .99라는 것입니다.실제로 확률이 0.99인 단어가 15개 이상 있는데 이는 처음 15개에 불과합니다. 불행하게도 이 이메일은 베이즈 규칙을 사용하는 지루한 예가 됩니다.흥미로운 다양한 확률을 보려면 실제로 매우 이례적인 스팸을 살펴봐야 합니다. 이 스팸에서 가장 흥미로운 15개의 단어와 확률은 다음과 같습니다. madam 0.99 Promotion 0.99 Republic 0.99 shortest 0.047225013 필수 0.047225013 표준화 0.07347802 죄송합니다 0.08221981 지원됨0.09019077 사람의 0.09019077 입력 0.9075001 품질 0.8921298 조직 0.12454646 투자 0.8568143 매우 0.14758544 가치 0.82347786 이번에는 증거가 좋은 것과 나쁜 것이 혼합되어 있습니다."가장 키가 작은"과 같은 단어는 "부인"이나 "승진"과 같은 단어가 유죄를 나타내는 것과 마찬가지로 무죄를 나타내는 증거입니다.그러나 여전히 유죄 판결이 더 강력합니다.베이즈 규칙에 따라 이 숫자를 결합하면 결과 확률은 .9027입니다. "Madam"은 분명히 "Dear Sir or Madam"으로 시작하는 스팸에서 나온 것입니다.흔하지는 않지만 내 합법적인 이메일에는 "madam"이라는 단어가 전혀 나오지 않으며 이는 비율에 관한 것입니다. "Republic"은 나이지리아 사기 이메일에 자주 등장하고 한국과 남아프리카를 언급하는 스팸에도 한두 번 나타나기 때문에 높은 점수를 받았습니다.스팸을 식별하는 데 도움이 되는 것은 우연이라고 말할 수 있습니다.하지만 스팸 가능성을 조사하면서 이러한 사고가 많이 발생하고 잘못된 방향이 아닌 올바른 방향으로 일을 추진하는 묘한 경향이 있다는 것을 발견했습니다.이 경우 나이지리아 사기 이메일에 "공화국"이라는 단어가 나오는 것은 전적으로 우연이 아닙니다.

ㄷ 이 스팸.저개발국을 포함하는 모호한 사업 제안의 전체 종류가 있으며, 이러한 제안은 공화국임을 명시적으로 지정하는 이름을 가질 가능성이 더 높습니다(그렇지 않기 때문에).[3] 반면에 "입력"은 정말 잘못된 것입니다.이는 주로 구독 취소 명령에서 발생하지만 여기서는 완전히 무해한 방식으로 사용됩니다.다행스럽게도 통계적 접근 방식은 매우 강력하며 결과가 폐기되기 전에 상당히 많은 실수를 허용할 수 있습니다. 비교를 위해 다음은 필터를 통과하는 스팸인 희귀한 새의 예입니다.왜?우연한 기회에 내 실제 이메일에 나오는 단어가 로드되기 때문입니다. perl 0.01 python 0.01 tcl 0.01 scripting 0.01 morris 0.01 graham 0.01491078 warranty 0.9762507 cgi 0.9734398 paul 0.027040077 꽤0.030676773 pop3 0.042199217 다양함 0.06080265 가격 0.9359873 관리됨 0.06451222 어려움 0.071706355 여기에 몇 가지 좋은 소식이 있습니다.첫째, 이 메일은 아마도 프로그래밍 언어를 전문으로 하지 않고 Morris라는 좋은 친구가 있는 사람의 필터를 통과하지 못할 것입니다.일반 사용자의 경우 여기에 있는 상위 5개 단어는 모두 중립적이며 스팸 가능성에 기여하지 않습니다. 둘째, 단어 쌍을 기반으로 한 필터링(아래 참조)이 "비용 효율적", "설정 비용", "환불" 등 꽤 의심스러운 항목을 포착할 수 있다고 생각합니다.그리고 물론 그들이 계속해서 나(또는 내가 속한 네트워크)에 스팸을 보내면 "Hostex" 자체가 스팸 용어로 인식될 것입니다. 마지막으로, 여기에 무고한 이메일이 있습니다.가장 흥미로운 15개의 단어는 다음과 같습니다: 연속 0.01 설명 0.01 연속 0.01 예제 0.033600237 프로그래밍 0.05214485 나는 0.055427782 예제 0.07972858 색상 0.9189189 로컬 호스트 0.09883721 안녕0.116539136 california 0.84421706 same 0.15981844 spot 0.1654587 us-ascii 0.16804294 what 0.19212411 여기에 있는 대부분의 단어는 메일이 무고한 메일임을 나타냅니다."color"(스패머는 컬러 글꼴을 좋아함)와 "California"(평가 및 양식의 메뉴에 나타남)라는 두 가지 불쾌한 냄새가 나는 단어가 있지만 "continuation" 및 "example"과 같은 분명히 무고한 단어보다 중요하기에는 충분하지 않습니다. "설명"이 완전히 무고하다고 평가하는 것은 흥미 롭습니다.4000통의 스팸메일 중 단 한 번도 그런 일이 발생하지 않았습니다.데이터는 그러한 놀라움으로 가득 차 있는 것으로 밝혀졌습니다.스팸 텍스트를 분석할 때 알게 되는 것 중 하나는 언어 스패머의 하위 집합이 얼마나 좁은 범위에서 작동하는지입니다. 개별 사용자 메일의 동일한 특성 어휘와 함께 베이지안 필터링이 좋은 선택이 된다는 사실입니다. 부록: 추가 아이디어아직 시도하지 않은 한 가지 아이디어는 개별 단어가 아닌 단어 쌍 또는 심지어 삼중 단어를 기준으로 필터링하는 것입니다.이렇게 하면 확률을 훨씬 더 정확하게 추정할 수 있습니다.예를 들어 현재 데이터베이스에서 "offers"라는 단어의 확률은 .96입니다.단어 쌍에 대한 확률을 기반으로 하면 확률이 .99인 "특별 제안"과 "가치 있는 제안"이 되고, 예를 들어 "접근 제안"("이 접근 방식 제안"에서와 같이)의 확률은 .1 이하가 됩니다. 제가 이 작업을 수행하지 않은 이유는 개별 단어를 기반으로 한 필터링이 이미 잘 작동하기 때문입니다.그러나 스팸을 탐지하기가 더 어려워진다면 필터를 강화할 여지가 있다는 의미입니다.(신기하게도 단어 쌍을 기반으로 한 필터는 실제로 역방향으로 실행되는 마르코프 체인 텍스트 생성기가 됩니다.) 특정 스팸 기능(예: 받는 사람: 필드에 수신자의 주소가 표시되지 않음)은 물론 스팸을 인식하는 데 가치가 있습니다.이 알고리즘에서는 가상 단어로 처리하여 고려할 수 있습니다.아마도 향후 버전에서는 최소한 가장 심각한 스팸 표시에 대해서는 이 작업을 수행할 것입니다.기능을 인식하는 스팸 필터는 많은 세부 사항에 적합합니다.그들에게 부족한 것은 증거를 결합하기 위한 전반적인 규율입니다. 스팸이 아닌 기능을 인식하는 것이 스팸 기능을 인식하는 것보다 더 중요할 수 있습니다.거짓 긍정(false positive)은 엄청난 걱정을 불러일으키기 때문에 특별함을 요구합니다.

조치.아마도 향후 버전에서는 오탐을 방지하기 위해 특별히 설계된 두 번째 수준의 테스트를 추가할 것입니다.메일이 이 두 번째 수준의 필터를 실행하면 스팸 확률이 임계값을 초과하더라도 허용됩니다. 이 두 번째 필터링 수준이 베이지안일 것이라고는 기대하지 않습니다.이는 필연적으로 임시적일 뿐만 아니라 추측에 기초할 것입니다. 왜냐하면 잘못된 긍정의 수가 패턴을 알아차릴 만큼 크지 않기 때문입니다.(백업 시스템이 기본 시스템과 동일한 기술에 의존하지 않는 경우에도 마찬가지입니다.) 앞으로 시도할 또 다른 방법은 이메일의 특정 부분에 특별한 주의를 기울이는 것입니다.예를 들어, 현재 스팸의 약 95%에는 귀하가 방문하길 원하는 사이트의 URL이 포함되어 있습니다.(나머지 5%는 전화번호로 전화하거나, 이메일이나 미국 메일 주소로 답장하거나, 어떤 경우에는 특정 주식을 구매하기를 원합니다.) 이러한 경우에는 URL 자체만으로 이메일이 스팸인지 여부를 판단하기에 충분합니다. 도메인 이름은 종종 여러 단어가 서로 붙어서 구성된다는 점에서 (비독일어) 이메일의 나머지 텍스트와 다릅니다.일반적인 경우에는 계산 비용이 많이 들지만 이를 분해해 볼 가치가 있습니다.필터가 "xxxporn" 토큰을 본 적이 없다면 개별 스팸 확률은 .4인 반면 "xxx"와 "porn"의 개별 확률은 각각 .9889와 .99이고 결합 확률은 .9998입니다. 스패머가 메시지 텍스트에서 유죄를 입증하는 단어 사용을 점차 중단하게 되면서 도메인 이름 분해가 더욱 중요해질 것으로 예상됩니다.(물론 IP 주소가 있는 URL은 몇몇 시스템 관리자의 메일을 제외하면 매우 범죄적인 신호입니다.) 스패머가 홍보하는 URL 목록을 협력적으로 관리하는 것이 좋습니다.악의적이거나 무능한 제출을 방지하려면 Raph Levien이 연구한 유형의 신뢰 측정 기준이 필요하지만, 그러한 기능이 있다면 모든 필터링 소프트웨어에 도움이 될 것입니다.이는 또한 보이콧을 위한 편리한 기반이 될 것입니다. 의심스러운 URL을 테스트하는 또 다른 방법은 사용자가 해당 사이트가 언급된 이메일을 보기 전에 사이트를 살펴보도록 크롤러를 보내는 것입니다.이메일을 평가하는 것처럼 베이지안 필터를 사용하여 사이트를 평가할 수 있으며 사이트에서 발견된 모든 내용은 이메일이 스팸일 확률을 계산하는 데 포함될 수 있습니다.물론 리디렉션으로 연결되는 URL은 특히 의심스럽습니다. 제가 정말 좋은 아이디어라고 생각하는 협력 프로젝트 중 하나는 거대한 스팸 모음을 축적하는 것입니다.베이지안 필터링이 제대로 작동하려면 크고 깨끗한 자료가 핵심입니다.베이지안 필터는 실제로 말뭉치를 입력으로 사용할 수 있습니다.그러나 그러한 말뭉치는 다른 종류의 필터에도 유용할 것입니다. 왜냐하면 그것을 테스트하는 데 사용될 수 있기 때문입니다. 그러한 말뭉치를 생성하는 것은 몇 가지 기술적인 문제를 야기합니다.물론 악의적이거나 무능한 제출을 방지하려면 신뢰 지표가 필요합니다.또한 말뭉치의 메일에서 개인 정보(받는 사람 주소 및 참조뿐만 아니라 수신 주소를 종종 인코딩하는 구독 취소 URL에 대한 인수)를 삭제하는 방법도 필요합니다.누구든지 이 프로젝트에 참여하고 싶다면 이는 세상에 좋은 일이 될 것입니다. 부록: 스팸 정의 스팸이 무엇인지에 대해서는 대략적인 합의가 있다고 생각하지만, 명확한 정의를 갖는 것이 유용할 것입니다.스팸의 중앙 자료를 구축하거나 스팸 필터링 비율을 의미 있게 비교하려면 이 작업을 수행해야 합니다. 우선 스팸은 원치 않는 상업용 이메일이 아닙니다.만약 내 이웃 사람이 내가 상태가 좋은 오래된 Raleigh 3단 변속기를 찾고 있다는 말을 듣고 나에게 하나를 팔겠다는 이메일을 보낸다면 나는 기뻐할 것입니다. 그러나 이 이메일은 상업적이면서도 원치 않는 이메일일 것입니다.스팸을 정의하는 특징(사실 스팸의 존재 이유)은 스팸이 원치 않는다는 것이 아니라 자동화된다는 것입니다. 또한 스팸이 일반적으로 상업적이라는 점도 우연일 뿐입니다.누군가가 정치적 명분을 지지하기 위해 대량 이메일을 보내기 시작했다면,

예를 들어, 그것은 포르노 사이트를 홍보하는 이메일만큼 스팸일 것입니다. 나는 스팸을 원치 않는 자동 이메일로 정의할 것을 제안합니다.따라서 이 정의에는 스팸에 대한 많은 법적 정의가 포함하지 않는 일부 이메일이 포함됩니다.아마도 로비스트의 영향을 받은 스팸의 법적 정의는 수신자와 "기존 관계"가 있는 회사가 보낸 메일을 제외하는 경향이 있습니다.그러나 예를 들어 회사에서 무언가를 구매한다고 해서 해당 회사로부터 지속적인 이메일을 요청했다는 의미는 아닙니다.온라인 상점에서 무언가를 주문한 후 스팸 스트림을 보내도 여전히 스팸입니다. 스팸을 보내는 회사는 종종 "구독 취소" 방법을 제공하거나 스팸 수신을 중단하려면 해당 사이트로 이동하여 "계정 기본 설정"을 변경하도록 요청합니다.이는 메일이 스팸이 되는 것을 막기에는 충분하지 않습니다.수신 거부를 하지 않는 것은 수신 동의와 동일하지 않습니다. 수신자가 이메일 수신을 요청하는 명확하게 라벨이 지정된 상자(기본값은 아니요)를 명시적으로 선택하지 않는 한 스팸입니다. 일부 비즈니스 관계에서는 암시적으로 특정 종류의 메일을 요청합니다.온라인으로 주문할 때 암묵적으로 영수증과 주문 배송 알림을 요청하는 것 같습니다.Verisign이 도메인 이름이 곧 만료된다는 경고 메일을 보내도 상관하지 않습니다(적어도 해당 도메인의 실제 등록 기관인 경우).그러나 Verisign이 전자 상거래 웹 사이트 구축에 대한 무료 가이드를 제공하는 이메일을 보내면 그것은 스팸입니다.참고:[1] 이 기사의 예제는 믿거나 말거나 접근성을 높이기 위해 Common Lisp로 번역되었습니다.여기에 설명된 애플리케이션은 아직 출시되지 않은 Arc라는 새로운 Lisp 방언을 테스트하기 위해 작성한 애플리케이션입니다.[2]현재 최저 요금은 스팸 100만 개를 보내는 데 약 200달러인 것으로 보입니다.스팸 하나당 50분의 1센트로 매우 저렴합니다.그러나 예를 들어 스팸의 95%를 필터링하면 스패머가 특정 대상에게 도달하는 데 드는 비용이 20배 증가합니다. 이를 흡수할 만큼 큰 마진을 가질 수 있는 사람은 거의 없습니다.[3]경험상, 국가 이름 앞에 수식어가 많을수록 통치자의 부패가 심합니다.X 사회주의 인민 민주 공화국이라는 나라는 아마도 당신이 살고 싶은 세상에서 마지막으로 살고 싶은 곳일 것입니다.초안을 읽어주신 Sarah Harlin에게 감사드립니다.필터링 및 메일 인프라 생성에 대한 몇 가지 좋은 아이디어를 제공한 Daniel Giffin(프로덕션 Arc 인터프리터도 작성 중)스팸에 관해 많은 토론을 해주신 Robert Morris, Trevor Blackwell 및 Erann Gat;신뢰 지표에 대한 조언을 주신 Raph Levien;통계에 대한 조언을 구한 Chip Coldwell과 Sam Steingold도 있습니다.Hackers & Painters에서 이 에세이와 다른 14개의 에세이를 찾을 수 있습니다.추가 정보:스팸 계획 FAQ더 나은 베이지안 필터링반격하는 필터필터가 스팸을 없앨까요?일본어 번역스페인어 번역중국어 번역확률스팸은 다릅니다필터 대 블랙리스트신뢰 지표필터링 연구Microsoft 특허슬래시닷 기사잘못된 방식LWN: 필터 비교CRM114는 99.87%를 얻습니다.

---

## 원문 (Original Essay)

Like to build things? Try Hacker News. August 2002(This article describes the spam-filtering techniques used in the spamproof web-based mail reader we built to exercise Arc. An improved algorithm is described in Better Bayesian Filtering.)I think it's possible to stop spam, and that content-based filters are the way to do it. The Achilles heel of the spammers is their message. They can circumvent any other barrier you set up. They have so far, at least. But they have to deliver their message, whatever it is. If we can write software that recognizes their messages, there is no way they can get around that._ _ _To the recipient, spam is easily recognizable. If you hired someone to read your mail and discard the spam, they would have little trouble doing it. How much do we have to do, short of AI, to automate this process?I think we will be able to solve the problem with fairly simple algorithms. In fact, I've found that you can filter present-day spam acceptably well using nothing more than a Bayesian combination of the spam probabilities of individual words. Using a slightly tweaked (as described below) Bayesian filter, we now miss less than 5 per 1000 spams, with 0 false positives.The statistical approach is not usually the first one people try when they write spam filters. Most hackers' first instinct is to try to write software that recognizes individual properties of spam. You look at spams and you think, the gall of these guys to try sending me mail that begins "Dear Friend" or has a subject line that's all uppercase and ends in eight exclamation points. I can filter out that stuff with about one line of code.And so you do, and in the beginning it works. A few simple rules will take a big bite out of your incoming spam. Merely looking for the word "click" will catch 79.7% of the emails in my spam corpus, with only 1.2% false positives.I spent about six months writing software that looked for individual spam features before I tried the statistical approach. What I found was that recognizing that last few percent of spams got very hard, and that as I made the filters stricter I got more false positives.False positives are innocent emails that get mistakenly identified as spams. For most users, missing legitimate email is an order of magnitude worse than receiving spam, so a filter that yields false positives is like an acne cure that carries a risk of death to the patient.The more spam a user gets, the less likely he'll be to notice one innocent mail sitting in his spam folder. And strangely enough, the better your spam filters get, the more dangerous false positives become, because when the filters are really good, users will be more likely to ignore everything they catch.I don't know why I avoided trying the statistical approach for so long. I think it was because I got addicted to trying to identify spam features myself, as if I were playing some kind of competitive game with the spammers. (Nonhackers don't often realize this, but most hackers are very competitive.) When I did try statistical analysis, I found immediately that it was much cleverer than I had been. It discovered, of course, that terms like "virtumundo" and "teens" were good indicators of spam. But it also discovered that "per" and "FL" and "ff0000" are good indicators of spam. In fact, "ff0000" (html for bright red) turns out to be as good an indicator of spam as any pornographic term._ _ _Here's a sketch of how I do statistical filtering. I start with one corpus of spam and one of nonspam mail. At the moment each one has about 4000 messages in it. I scan the entire text, including headers and embedded html and javascript, of each message in each corpus. I currently consider alphanumeric characters, dashes, apostrophes, and dollar signs to be part of tokens, and everything else to be a token separator. (There is probably room for improvement here.) I ignore tokens that are all digits, and I also ignore html comments, not even considering them as token separators.I count the number of times each token (ignoring case, currently) occurs in each corpus. At this stage I end up with two large hash tables, one for each corpus, mapping tokens to number of occurrences.Next I create a third hash table, this time mapping each token to the probability that an email containing it is a spam, which I calculate as follows [1]: (let ((g (* 2 (or (gethash word good) 0))) (b (or (gethash word bad) 0))) (unless (< (+ g b) 5) (max .01 (min .99 (float (/ (min 1 (/ b nbad)) (+ (min 1 (/ g ngood)) (min 1 (/ b nbad))))))))) where word is the token whose probability we're calculating, good and bad are the hash tables I created in the first step, and ngood and nbad are the number of nonspam and spam messages respectively.I explained this as code to show a couple of important details. I want to bias the probabilities slightly to avoid false positives, and by trial and error I've found that a good way to do it is to double all the numbers in good. This helps to distinguish between words that occasionally do occur in legitimate email and words that almost never do. I only consider words that occur more than five times in total (actually, because of the doubling, occurring three times in nonspam mail would be enough). And then there is the question of what probability to assign to words that occur in one corpus but not the other. Again by trial and error I chose .01 and .99. There may be room for tuning here, but as the corpus grows such tuning will happen automatically anyway.The especially observant will notice that while I consider each corpus to be a single long stream of text for purposes of counting occurrences, I use the number of emails in each, rather than their combined length, as the divisor in calculating spam probabilities. This adds another slight bias to protect against false positives.When new mail arrives, it is scanned into tokens, and the most interesting fifteen tokens, where interesting is measured by how far their spam probability is from a neutral .5, are used to calculate the probability that the mail is spam. If probs is a list of the fifteen individual probabilities, you calculate the combined probability thus: (let ((prod (apply #'* probs))) (/ prod (+ prod (apply #'* (mapcar #'(lambda (x) (- 1 x)) probs))))) One question that arises in practice is what probability to assign to a word you've never seen, i.e. one that doesn't occur in the hash table of word probabilities. I've found, again by trial and error, that .4 is a good number to use. If you've never seen a word before, it is probably fairly innocent; spam words tend to be all too familiar.There are examples of this algorithm being applied to actual emails in an appendix at the end.I treat mail as spam if the algorithm above gives it a probability of more than .9 of being spam. But in practice it would not matter much where I put this threshold, because few probabilities end up in the middle of the range._ _ _One great advantage of the statistical approach is that you don't have to read so many spams. Over the past six months, I've read literally thousands of spams, and it is really kind of demoralizing. Norbert Wiener said if you compete with slaves you become a slave, and there is something similarly degrading about competing with spammers. To recognize individual spam features you have to try to get into the mind of the spammer, and frankly I want to spend as little time inside the minds of spammers as possible.But the real advantage of the Bayesian approach, of course, is that you know what you're measuring. Feature-recognizing filters like SpamAssassin assign a spam "score" to email. The Bayesian approach assigns an actual probability. The problem with a "score" is that no one knows what it means. The user doesn't know what it means, but worse still, neither does the developer of the filter. How many points should an email get for having the word "sex" in it? A probability can of course be mistaken, but there is little ambiguity about what it means, or how evidence should be combined to calculate it. Based on my corpus, "sex" indicates a .97 probability of the containing email being a spam, whereas "sexy" indicates .99 probability. And Bayes' Rule, equally unambiguous, says that an email containing both words would, in the (unlikely) absence of any other evidence, have a 99.97% chance of being a spam.Because it is measuring probabilities, the Bayesian approach considers all the evidence in the email, both good and bad. Words that occur disproportionately rarely in spam (like "though" or "tonight" or "apparently") contribute as much to decreasing the probability as bad words like "unsubscribe" and "opt-in" do to increasing it. So an otherwise innocent email that happens to include the word "sex" is not going to get tagged as spam.Ideally, of course, the probabilities should be calculated individually for each user. I get a lot of email containing the word "Lisp", and (so far) no spam that does. So a word like that is effectively a kind of password for sending mail to me. In my earlier spam-filtering software, the user could set up a list of such words and mail containing them would automatically get past the filters. On my list I put words like "Lisp" and also my zipcode, so that (otherwise rather spammy-sounding) receipts from online orders would get through. I thought I was being very clever, but I found that the Bayesian filter did the same thing for me, and moreover discovered of a lot of words I hadn't thought of.When I said at the start that our filters let through less than 5 spams per 1000 with 0 false positives, I'm talking about filtering my mail based on a corpus of my mail. But these numbers are not misleading, because that is the approach I'm advocating: filter each user's mail based on the spam and nonspam mail he receives. Essentially, each user should have two delete buttons, ordinary delete and delete-as-spam. Anything deleted as spam goes into the spam corpus, and everything else goes into the nonspam corpus.You could start users with a seed filter, but ultimately each user should have his own per-word probabilities based on the actual mail he receives. This (a) makes the filters more effective, (b) lets each user decide their own precise definition of spam, and (c) perhaps best of all makes it hard for spammers to tune mails to get through the filters. If a lot of the brain of the filter is in the individual databases, then merely tuning spams to get through the seed filters won't guarantee anything about how well they'll get through individual users' varying and much more trained filters.Content-based spam filtering is often combined with a whitelist, a list of senders whose mail can be accepted with no filtering. One easy way to build such a whitelist is to keep a list of every address the user has ever sent mail to. If a mail reader has a delete-as-spam button then you could also add the from address of every email the user has deleted as ordinary trash.I'm an advocate of whitelists, but more as a way to save computation than as a way to improve filtering. I used to think that whitelists would make filtering easier, because you'd only have to filter email from people you'd never heard from, and someone sending you mail for the first time is constrained by convention in what they can say to you. Someone you already know might send you an email talking about sex, but someone sending you mail for the first time would not be likely to. The problem is, people can have more than one email address, so a new from-address doesn't guarantee that the sender is writing to you for the first time. It is not unusual for an old friend (especially if he is a hacker) to suddenly send you an email with a new from-address, so you can't risk false positives by filtering mail from unknown addresses especially stringently.In a sense, though, my filters do themselves embody a kind of whitelist (and blacklist) because they are based on entire messages, including the headers. So to that extent they "know" the email addresses of trusted senders and even the routes by which mail gets from them to me. And they know the same about spam, including the server names, mailer versions, and protocols._ _ _If I thought that I could keep up current rates of spam filtering, I would consider this problem solved. But it doesn't mean much to be able to filter out most present-day spam, because spam evolves. Indeed, most antispam techniques so far have been like pesticides that do nothing more than create a new, resistant strain of bugs.I'm more hopeful about Bayesian filters, because they evolve with the spam. So as spammers start using "c0ck" instead of "cock" to evade simple-minded spam filters based on individual words, Bayesian filters automatically notice. Indeed, "c0ck" is far more damning evidence than "cock", and Bayesian filters know precisely how much more.Still, anyone who proposes a plan for spam filtering has to be able to answer the question: if the spammers knew exactly what you were doing, how well could they get past you? For example, I think that if checksum-based spam filtering becomes a serious obstacle, the spammers will just switch to mad-lib techniques for generating message bodies.To beat Bayesian filters, it would not be enough for spammers to make their emails unique or to stop using individual naughty words. They'd have to make their mails indistinguishable from your ordinary mail. And this I think would severely constrain them. Spam is mostly sales pitches, so unless your regular mail is all sales pitches, spams will inevitably have a different character. And the spammers would also, of course, have to change (and keep changing) their whole infrastructure, because otherwise the headers would look as bad to the Bayesian filters as ever, no matter what they did to the message body. I don't know enough about the infrastructure that spammers use to know how hard it would be to make the headers look innocent, but my guess is that it would be even harder than making the message look innocent.Assuming they could solve the problem of the headers, the spam of the future will probably look something like this: Hey there. Thought you should check out the following: http://www.27meg.com/foo because that is about as much sales pitch as content-based filtering will leave the spammer room to make. (Indeed, it will be hard even to get this past filters, because if everything else in the email is neutral, the spam probability will hinge on the url, and it will take some effort to make that look neutral.)Spammers range from businesses running so-called opt-in lists who don't even try to conceal their identities, to guys who hijack mail servers to send out spams promoting porn sites. If we use filtering to whittle their options down to mails like the one above, that should pretty much put the spammers on the "legitimate" end of the spectrum out of business; they feel obliged by various state laws to include boilerplate about why their spam is not spam, and how to cancel your "subscription," and that kind of text is easy to recognize.(I used to think it was naive to believe that stricter laws would decrease spam. Now I think that while stricter laws may not decrease the amount of spam that spammers send, they can certainly help filters to decrease the amount of spam that recipients actually see.)All along the spectrum, if you restrict the sales pitches spammers can make, you will inevitably tend to put them out of business. That word business is an important one to remember. The spammers are businessmen. They send spam because it works. It works because although the response rate is abominably low (at best 15 per million, vs 3000 per million for a catalog mailing), the cost, to them, is practically nothing. The cost is enormous for the recipients, about 5 man-weeks for each million recipients who spend a second to delete the spam, but the spammer doesn't have to pay that.Sending spam does cost the spammer something, though. [2] So the lower we can get the response rate-- whether by filtering, or by using filters to force spammers to dilute their pitches-- the fewer businesses will find it worth their while to send spam.The reason the spammers use the kinds of sales pitches that they do is to increase response rates. This is possibly even more disgusting than getting inside the mind of a spammer, but let's take a quick look inside the mind of someone who responds to a spam. This person is either astonishingly credulous or deeply in denial about their sexual interests. In either case, repulsive or idiotic as the spam seems to us, it is exciting to them. The spammers wouldn't say these things if they didn't sound exciting. And "thought you should check out the following" is just not going to have nearly the pull with the spam recipient as the kinds of things that spammers say now. Result: if it can't contain exciting sales pitches, spam becomes less effective as a marketing vehicle, and fewer businesses want to use it.That is the big win in the end. I started writing spam filtering software because I didn't want have to look at the stuff anymore. But if we get good enough at filtering out spam, it will stop working, and the spammers will actually stop sending it._ _ _Of all the approaches to fighting spam, from software to laws, I believe Bayesian filtering will be the single most effective. But I also think that the more different kinds of antispam efforts we undertake, the better, because any measure that constrains spammers will tend to make filtering easier. And even within the world of content-based filtering, I think it will be a good thing if there are many different kinds of software being used simultaneously. The more different filters there are, the harder it will be for spammers to tune spams to get through them. Appendix: Examples of FilteringHere is an example of a spam that arrived while I was writing this article. The fifteen most interesting words in this spam are: qvp0045 indira mx-05 intimail $7500 freeyankeedom cdo bluefoxmedia jpg unsecured platinum 3d0 qves 7c5 7c266675 The words are a mix of stuff from the headers and from the message body, which is typical of spam. Also typical of spam is that every one of these words has a spam probability, in my database, of .99. In fact there are more than fifteen words with probabilities of .99, and these are just the first fifteen seen.Unfortunately that makes this email a boring example of the use of Bayes' Rule. To see an interesting variety of probabilities we have to look at this actually quite atypical spam.The fifteen most interesting words in this spam, with their probabilities, are: madam 0.99 promotion 0.99 republic 0.99 shortest 0.047225013 mandatory 0.047225013 standardization 0.07347802 sorry 0.08221981 supported 0.09019077 people's 0.09019077 enter 0.9075001 quality 0.8921298 organization 0.12454646 investment 0.8568143 very 0.14758544 valuable 0.82347786 This time the evidence is a mix of good and bad. A word like "shortest" is almost as much evidence for innocence as a word like "madam" or "promotion" is for guilt. But still the case for guilt is stronger. If you combine these numbers according to Bayes' Rule, the resulting probability is .9027."Madam" is obviously from spams beginning "Dear Sir or Madam." They're not very common, but the word "madam" never occurs in my legitimate email, and it's all about the ratio."Republic" scores high because it often shows up in Nigerian scam emails, and also occurs once or twice in spams referring to Korea and South Africa. You might say that it's an accident that it thus helps identify this spam. But I've found when examining spam probabilities that there are a lot of these accidents, and they have an uncanny tendency to push things in the right direction rather than the wrong one. In this case, it is not entirely a coincidence that the word "Republic" occurs in Nigerian scam emails and this spam. There is a whole class of dubious business propositions involving less developed countries, and these in turn are more likely to have names that specify explicitly (because they aren't) that they are republics.[3]On the other hand, "enter" is a genuine miss. It occurs mostly in unsubscribe instructions, but here is used in a completely innocent way. Fortunately the statistical approach is fairly robust, and can tolerate quite a lot of misses before the results start to be thrown off.For comparison, here is an example of that rare bird, a spam that gets through the filters. Why? Because by sheer chance it happens to be loaded with words that occur in my actual email: perl 0.01 python 0.01 tcl 0.01 scripting 0.01 morris 0.01 graham 0.01491078 guarantee 0.9762507 cgi 0.9734398 paul 0.027040077 quite 0.030676773 pop3 0.042199217 various 0.06080265 prices 0.9359873 managed 0.06451222 difficult 0.071706355 There are a couple pieces of good news here. First, this mail probably wouldn't get through the filters of someone who didn't happen to specialize in programming languages and have a good friend called Morris. For the average user, all the top five words here would be neutral and would not contribute to the spam probability.Second, I think filtering based on word pairs (see below) might well catch this one: "cost effective", "setup fee", "money back" -- pretty incriminating stuff. And of course if they continued to spam me (or a network I was part of), "Hostex" itself would be recognized as a spam term.Finally, here is an innocent email. Its fifteen most interesting words are as follows: continuation 0.01 describe 0.01 continuations 0.01 example 0.033600237 programming 0.05214485 i'm 0.055427782 examples 0.07972858 color 0.9189189 localhost 0.09883721 hi 0.116539136 california 0.84421706 same 0.15981844 spot 0.1654587 us-ascii 0.16804294 what 0.19212411 Most of the words here indicate the mail is an innocent one. There are two bad smelling words, "color" (spammers love colored fonts) and "California" (which occurs in testimonials and also in menus in forms), but they are not enough to outweigh obviously innocent words like "continuation" and "example".It's interesting that "describe" rates as so thoroughly innocent. It hasn't occurred in a single one of my 4000 spams. The data turns out to be full of such surprises. One of the things you learn when you analyze spam texts is how narrow a subset of the language spammers operate in. It's that fact, together with the equally characteristic vocabulary of any individual user's mail, that makes Bayesian filtering a good bet.Appendix: More IdeasOne idea that I haven't tried yet is to filter based on word pairs, or even triples, rather than individual words. This should yield a much sharper estimate of the probability. For example, in my current database, the word "offers" has a probability of .96. If you based the probabilities on word pairs, you'd end up with "special offers" and "valuable offers" having probabilities of .99 and, say, "approach offers" (as in "this approach offers") having a probability of .1 or less.The reason I haven't done this is that filtering based on individual words already works so well. But it does mean that there is room to tighten the filters if spam gets harder to detect. (Curiously, a filter based on word pairs would be in effect a Markov-chaining text generator running in reverse.)Specific spam features (e.g. not seeing the recipient's address in the to: field) do of course have value in recognizing spam. They can be considered in this algorithm by treating them as virtual words. I'll probably do this in future versions, at least for a handful of the most egregious spam indicators. Feature-recognizing spam filters are right in many details; what they lack is an overall discipline for combining evidence.Recognizing nonspam features may be more important than recognizing spam features. False positives are such a worry that they demand extraordinary measures. I will probably in future versions add a second level of testing designed specifically to avoid false positives. If a mail triggers this second level of filters it will be accepted even if its spam probability is above the threshold.I don't expect this second level of filtering to be Bayesian. It will inevitably be not only ad hoc, but based on guesses, because the number of false positives will not tend to be large enough to notice patterns. (It is just as well, anyway, if a backup system doesn't rely on the same technology as the primary system.)Another thing I may try in the future is to focus extra attention on specific parts of the email. For example, about 95% of current spam includes the url of a site they want you to visit. (The remaining 5% want you to call a phone number, reply by email or to a US mail address, or in a few cases to buy a certain stock.) The url is in such cases practically enough by itself to determine whether the email is spam.Domain names differ from the rest of the text in a (non-German) email in that they often consist of several words stuck together. Though computationally expensive in the general case, it might be worth trying to decompose them. If a filter has never seen the token "xxxporn" before it will have an individual spam probability of .4, whereas "xxx" and "porn" individually have probabilities (in my corpus) of .9889 and .99 respectively, and a combined probability of .9998.I expect decomposing domain names to become more important as spammers are gradually forced to stop using incriminating words in the text of their messages. (A url with an ip address is of course an extremely incriminating sign, except in the mail of a few sysadmins.)It might be a good idea to have a cooperatively maintained list of urls promoted by spammers. We'd need a trust metric of the type studied by Raph Levien to prevent malicious or incompetent submissions, but if we had such a thing it would provide a boost to any filtering software. It would also be a convenient basis for boycotts.Another way to test dubious urls would be to send out a crawler to look at the site before the user looked at the email mentioning it. You could use a Bayesian filter to rate the site just as you would an email, and whatever was found on the site could be included in calculating the probability of the email being a spam. A url that led to a redirect would of course be especially suspicious.One cooperative project that I think really would be a good idea would be to accumulate a giant corpus of spam. A large, clean corpus is the key to making Bayesian filtering work well. Bayesian filters could actually use the corpus as input. But such a corpus would be useful for other kinds of filters too, because it could be used to test them.Creating such a corpus poses some technical problems. We'd need trust metrics to prevent malicious or incompetent submissions, of course. We'd also need ways of erasing personal information (not just to-addresses and ccs, but also e.g. the arguments to unsubscribe urls, which often encode the to-address) from mails in the corpus. If anyone wants to take on this project, it would be a good thing for the world.Appendix: Defining SpamI think there is a rough consensus on what spam is, but it would be useful to have an explicit definition. We'll need to do this if we want to establish a central corpus of spam, or even to compare spam filtering rates meaningfully.To start with, spam is not unsolicited commercial email. If someone in my neighborhood heard that I was looking for an old Raleigh three-speed in good condition, and sent me an email offering to sell me one, I'd be delighted, and yet this email would be both commercial and unsolicited. The defining feature of spam (in fact, its raison d'etre) is not that it is unsolicited, but that it is automated.It is merely incidental, too, that spam is usually commercial. If someone started sending mass email to support some political cause, for example, it would be just as much spam as email promoting a porn site.I propose we define spam as unsolicited automated email. This definition thus includes some email that many legal definitions of spam don't. Legal definitions of spam, influenced presumably by lobbyists, tend to exclude mail sent by companies that have an "existing relationship" with the recipient. But buying something from a company, for example, does not imply that you have solicited ongoing email from them. If I order something from an online store, and they then send me a stream of spam, it's still spam.Companies sending spam often give you a way to "unsubscribe," or ask you to go to their site and change your "account preferences" if you want to stop getting spam. This is not enough to stop the mail from being spam. Not opting out is not the same as opting in. Unless the recipient explicitly checked a clearly labelled box (whose default was no) asking to receive the email, then it is spam.In some business relationships, you do implicitly solicit certain kinds of mail. When you order online, I think you implicitly solicit a receipt, and notification when the order ships. I don't mind when Verisign sends me mail warning that a domain name is about to expire (at least, if they are the actual registrar for it). But when Verisign sends me email offering a FREE Guide to Building My E-Commerce Web Site, that's spam. Notes:[1] The examples in this article are translated into Common Lisp for, believe it or not, greater accessibility. The application described here is one that we wrote in order to test a new Lisp dialect called Arc that is not yet released.[2] Currently the lowest rate seems to be about $200 to send a million spams. That's very cheap, 1/50th of a cent per spam. But filtering out 95% of spam, for example, would increase the spammers' cost to reach a given audience by a factor of 20. Few can have margins big enough to absorb that.[3] As a rule of thumb, the more qualifiers there are before the name of a country, the more corrupt the rulers. A country called The Socialist People's Democratic Republic of X is probably the last place in the world you'd want to live. Thanks to Sarah Harlin for reading drafts of this; Daniel Giffin (who is also writing the production Arc interpreter) for several good ideas about filtering and for creating our mail infrastructure; Robert Morris, Trevor Blackwell and Erann Gat for many discussions about spam; Raph Levien for advice about trust metrics; and Chip Coldwell and Sam Steingold for advice about statistics. You'll find this essay and 14 others in Hackers & Painters. More Info:Plan for Spam FAQBetter Bayesian FilteringFilters that Fight BackWill Filters Kill Spam?Japanese TranslationSpanish TranslationChinese TranslationProbabilitySpam is DifferentFilters vs. BlacklistsTrust MetricsFiltering ResearchMicrosoft PatentSlashdot ArticleThe Wrong WayLWN: Filter ComparisonCRM114 gets 99.87%

---

_분석일: 2025. 11. 29._
_수집일: 2025. 11. 28._
